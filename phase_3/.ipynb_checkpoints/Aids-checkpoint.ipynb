{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from nltk import TweetTokenizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following: https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f\n",
    "\n",
    "# Loading BERT and trying stuff out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the pretrained model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,   146,  1209,  2824,  2508, 26173,  3568,   102,     0,     0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "example_text = 'I will watch Memento tonight'\n",
    "\n",
    "bert_input = tokenizer(example_text, # specifying the text/file\n",
    "                       padding='max_length', # to pad each sequence to a length we specify with max_length\n",
    "                       max_length=10, # The max length of each sequence. We should use 512 since that's the max length with BERT\n",
    "                       truncation=True, # If True, then any tokens over our max length will be cut-off\n",
    "                       return_tensors='pt') # The type of tensors that will be returned pt for pytorch, tf for tensorflow\n",
    "\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['token_type_ids'])\n",
    "print(bert_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is input_ids?\n",
    "\n",
    "This is the id representation of each token, which can be decoded into actual tokens like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] I will watch Memento tonight [SEP] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "example_text = tokenizer.decode(bert_input.input_ids[0])\n",
    "\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the BertTokenizer takes care of the necessary transformations of the input text such that it's ready to be used as an input for our BERT model.\n",
    "\n",
    "It adds the [CLS], [SEP], and [PAD] tokens that we need.\n",
    "\n",
    "Since the max_length = 10 we get the two [PAD] tokens at the end to make the length 10.\n",
    "\n",
    "# What is token_type_ids?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary mask which identifies in which sequence a token belongs. If we have only a single sequence, then all of the token type ids will be 0. For a text classification task, token_type_ids is an optional input for our BERT model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is attention_mask\n",
    "\n",
    "This is a binary mask which identifies whether a word is a real word or just padding. If the token contains [CLS], [SEP], or any real word, then the mask would be 1. If the token is just [PAD], then the mask would be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Note\n",
    "\n",
    "We are using the BertTokenizer from bert-base-cased, which is a pre-trained BERT model that works well on English data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(filepath, padding = False):\n",
    "    train_vocab = {}\n",
    "    train = gzip.open(filepath)\n",
    "    counter1 = 0\n",
    "    counter2 = 0\n",
    "    counter3 = 0\n",
    "    counter = 0\n",
    "    if padding: \n",
    "        train_vocab['<PAD>'] = 0\n",
    "        counter2 += 1\n",
    "    no_reviewText = []\n",
    "    labels = {}\n",
    "    sentences = {}\n",
    "    tokenizer = TweetTokenizer()\n",
    "    for line in train:\n",
    "        counter1 +=1\n",
    "        #print(line)\n",
    "        if 'reviewText' in json.loads(line).keys():\n",
    "            a = json.loads(line)\n",
    "            sentences[counter3] = a['reviewText']\n",
    "            counter3 += 1\n",
    "            if a['sentiment'] == 'positive':\n",
    "                labels[counter] = 1\n",
    "            elif a['sentiment'] == 'negative': \n",
    "                labels[counter] = 0\n",
    "            counter +=1\n",
    "            for word in tokenizer.tokenize(json.loads(line)['reviewText']):\n",
    "                if word not in train_vocab.keys():\n",
    "                    train_vocab[word] = counter2\n",
    "                    counter2 += 1\n",
    "        else:\n",
    "            no_reviewText.append(counter1)\n",
    "    final_dict = {'line_count' : counter1,\n",
    "                 'review_count' : counter3,\n",
    "                 'vocab_size' : counter2,\n",
    "                 'no_text_reviews' : no_reviewText,\n",
    "                 'labels' : labels,\n",
    "                 'vocabulary' : train_vocab,\n",
    "                 'sentences' : sentences}\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = build_vocab('../classification/music_reviews_train.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipped_to_pandas(filepath):\n",
    "    data = gzip.open(filepath)\n",
    "    df = pd.DataFrame(columns=['reviewText', 'sentiment'])\n",
    "\n",
    "    for line in data:\n",
    "        dicted = json.loads(line)\n",
    "        if 'reviewText' not in dicted:\n",
    "            reviewText = 'Null'\n",
    "        else:\n",
    "            reviewText = dicted['reviewText']\n",
    "\n",
    "        if 'sentiment' not in dicted:\n",
    "            sentiment = 'Null'\n",
    "        else:\n",
    "            sentiment = dicted['sentiment']\n",
    "\n",
    "        filtered_dict = {'reviewText': [reviewText], 'sentiment': [sentiment]}\n",
    "        temp_df = pd.DataFrame.from_dict(filtered_dict)\n",
    "        df = pd.concat([df, temp_df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So creative!  Love his music - the words, the ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This tape can hardly be understood and it was ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buy the CD.  Do not buy the MP3 album.  Downlo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love Dallas Holms music and voice!  Thank Yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great memories of my early years in Christ</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText sentiment\n",
       "0  So creative!  Love his music - the words, the ...  positive\n",
       "0  This tape can hardly be understood and it was ...  negative\n",
       "0  Buy the CD.  Do not buy the MP3 album.  Downlo...  negative\n",
       "0  I love Dallas Holms music and voice!  Thank Yo...  positive\n",
       "0         Great memories of my early years in Christ  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = zipped_to_pandas('../classification/music_reviews_train.json.gz')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My dentist recommended this as a relaxation te...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am personally acquainted with a member of th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Cd cover was broken when I got it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is an uplifting, keep going, motivating s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought this vinyl 2 times and they won't exc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText sentiment\n",
       "0  My dentist recommended this as a relaxation te...  positive\n",
       "0  I am personally acquainted with a member of th...  negative\n",
       "0              The Cd cover was broken when I got it  negative\n",
       "0  This is an uplifting, keep going, motivating s...  positive\n",
       "0  I bought this vinyl 2 times and they won't exc...  negative"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = zipped_to_pandas('../classification/music_reviews_dev.json.gz')\n",
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(filepath, padding = False):\n",
    "    train_vocab = {}\n",
    "    train = gzip.open(filepath)\n",
    "    counter1 = 0\n",
    "    counter2 = 0\n",
    "    counter3 = 0\n",
    "    counter = 0\n",
    "    if padding: \n",
    "        train_vocab['<PAD>'] = 0\n",
    "        counter2 += 1\n",
    "    no_reviewText = []\n",
    "    labels = {}\n",
    "    sentences = {}\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "    for line in train:\n",
    "        counter1 +=1\n",
    "        #print(line)\n",
    "        if 'reviewText' in json.loads(line).keys():\n",
    "            a = json.loads(line)\n",
    "            sentences[counter3] = a['reviewText']\n",
    "            counter3 += 1\n",
    "            if a['sentiment'] == 'positive':\n",
    "                labels[counter] = 1\n",
    "            elif a['sentiment'] == 'negative': \n",
    "                labels[counter] = 0\n",
    "            counter +=1\n",
    "            for word in tokenizer.tokenize(json.loads(line)['reviewText']):\n",
    "                if word not in train_vocab.keys():\n",
    "                    train_vocab[word] = counter2\n",
    "                    counter2 += 1\n",
    "        else:\n",
    "            no_reviewText.append(counter1)\n",
    "    final_dict = {'line_count' : counter1,\n",
    "                 'review_count' : counter3,\n",
    "                 'vocab_size' : counter2,\n",
    "                 'no_text_reviews' : no_reviewText,\n",
    "                 'labels' : labels,\n",
    "                 'vocabulary' : train_vocab,\n",
    "                 'sentences' : sentences}\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = build_vocab('../classification/music_reviews_train.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class\n",
    "\n",
    "Now that we know how shit works, let's build a Dataset class for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'negative': 0,\n",
    "          'positive': 1,\n",
    "          'Null': 2}\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['sentiment']]\n",
    "        self.texts = [tokenizer(text,\n",
    "                                padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['reviewText']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "    \n",
    "    def get_batch_text(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return self.texts[idx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "    \n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
