{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project phase 1: Baseline\n",
    "\n",
    "The goal of this phase is to create a baseline model. Note that the word baseline can mean different things. In the course we distinguished three different types of baselines:\n",
    "* 1. The simplest possible approach (majority baseline, i.e. everything is positive or noun)\n",
    "* 2. A simple machine learning classifier (logistic regression with words as features)\n",
    "* 3. The ``state-of-the-art'' approach on which you want to improve (your starting point)\n",
    "\n",
    "For this phase you need to make a number 2 or 3 baseline. \n",
    "\n",
    "If you plan to have a research question like: can we improve sentiment detection systems by doing X, the answer to the question is the most relevant if you have a competetive baseline (3). In this case we would suggest to use a BiLSTM or even a transformer based model, so that you can re-use the baseline for the final research question (phase 3).\n",
    "\n",
    "You should pick one of the following tasks to create your baseline for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Sentiment classification\n",
    "* The data can be found in the `classification` folder.\n",
    "* The goal is to predict the label in the `sentiment` field.\n",
    "* **You have to upload the predictions of `music_reviews_test_masked.json.gz` to CodaLab. (The link will be posted here on monday). Note that the format should match the json files in the repository.**\n",
    "* **Also upload a .txt file on LearnIt (one per group) with a short description of your baseline.**\n",
    "\n",
    "The data can be read like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"vote\": 3\n",
      "\"verified\": True\n",
      "\"reviewTime\": 12 19, 2012\n",
      "\"reviewerID\": A1KKWETTT5BZ6N\n",
      "\"asin\": B00474S1J2\n",
      "\"reviewText\": My dentist recommended this as a relaxation technique for dental visits. They give me an ipod with headphones, play this on it and it relieves some of the stress of dental treatment, which I dislike intensely.\n",
      "It worked so well that I bought my own copy to try at home. I fall asleep after a couple of minutes and stay asleep. Instead of tossing and turning, I hardly move at all. Highly recommend.\n",
      "\"summary\": Out like a light!\n",
      "\"unixReviewTime\": 1355875200\n",
      "\"sentiment\": positive\n",
      "\"id\": 0\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "for line in gzip.open('classification/music_reviews_dev.json.gz'):\n",
    "    review_data = json.loads(line)\n",
    "    for key in review_data:\n",
    "        print('\"' + key +'\": ' + str(review_data[key]))\n",
    "    break\n",
    "paths = {'train':'classification/music_reviews_train.json.gz',\n",
    "        'test':'classification/music_reviews_test_masked.json.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99946 226347\n"
     ]
    }
   ],
   "source": [
    "train_vocab = {}\n",
    "train = gzip.open(paths['train'])\n",
    "counter1 = 0\n",
    "counter2 = 0\n",
    "counter3 = 0\n",
    "train_no_reviewText = []\n",
    "labels = {}\n",
    "train_sentences = {}\n",
    "for line in train:\n",
    "    counter1 +=1\n",
    "    #print(line)\n",
    "    if 'reviewText' in json.loads(line).keys():\n",
    "        train_sentences[counter3] = json.loads(line)['reviewText']\n",
    "        counter3 += 1\n",
    "        for word in json.loads(line)['reviewText'].split():\n",
    "            if word not in train_vocab.keys():\n",
    "                train_vocab[word] = counter2\n",
    "                counter2 += 1\n",
    "    else:\n",
    "        train_no_reviewText.append(counter1)\n",
    "print(counter3,counter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gram matrix \n",
    "m1 = torch.zeros(counter3, counter2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need idx2word\n",
    "idx2word = dict([(value, key) for key, value in train_vocab.items()])\n",
    "\n",
    "# Begin correcting gram matrix\n",
    "\n",
    "for sen in train_sentences: \n",
    "    for word in train_sentences[sen].split(): \n",
    "        m1[sen, train_vocab[word]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226347"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vocab = {}\n",
    "train = gzip.open(paths['train'])\n",
    "train_labels = {}\n",
    "counter = 0\n",
    "for line in train:\n",
    "    a = json.loads(line)\n",
    "    if 'reviewText' in a.keys():\n",
    "        if a['sentiment'] == 'positive':\n",
    "            train_labels[counter] = 1\n",
    "        elif a['sentiment'] == 'negative': \n",
    "            train_labels[counter] = 0\n",
    "        counter +=1\n",
    "\n",
    "        \n",
    "#len(labels)\n",
    "#print(type(labels))\n",
    "\n",
    "\n",
    "\n",
    "counter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 226347])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n",
      "torch.Size([5000, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "num_batches = int(len(m1)/batch_size)\n",
    "train_feats_batches = m1[:batch_size*num_batches].view(num_batches,batch_size, counter2)\n",
    "for feats_batch in train_feats_batches:\n",
    "    print(feats_batch.shape)\n",
    "\n",
    "bingus = list(train_labels.values())\n",
    "bingus = torch.FloatTensor(bingus)\n",
    "\n",
    "num_batches = int(len(bingus)/batch_size)\n",
    "train_label_batches = bingus[:batch_size*num_batches].view(num_batches,batch_size,1)\n",
    "counter = 1\n",
    "for feats_batch in train_label_batches:\n",
    "    counter+=1\n",
    "    print(feats_batch.shape)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  397685\n",
      "m2 constructed!\n",
      "idx2word done!\n",
      "Gram matrix done\n",
      "Labels noted!\n",
      "Feature Matrix shapes: \n",
      "torch.Size([2499, 226347])\n",
      "torch.Size([2499, 226347])\n",
      "torch.Size([2499, 226347])\n",
      "label matrix shapes: \n"
     ]
    }
   ],
   "source": [
    "# Encode test labels\n",
    "test_vocab = {}\n",
    "test = gzip.open(paths['test'])\n",
    "counter1 = 0\n",
    "counter2 = 0\n",
    "counter3 = 0\n",
    "test_no_reviewText = []\n",
    "test_labels = {}\n",
    "test_sentences = {}\n",
    "for line in test:\n",
    "    counter1 +=1\n",
    "    #print(line)\n",
    "    if 'reviewText' in json.loads(line).keys():\n",
    "        test_sentences[counter3] = json.loads(line)['reviewText']\n",
    "        counter3 += 1\n",
    "        for word in json.loads(line)['reviewText'].split():\n",
    "            if word not in train_vocab.keys():\n",
    "                test_vocab[word] = counter2\n",
    "                counter2 += 1\n",
    "    else:\n",
    "        test_no_reviewText.append(counter1)\n",
    "print('Vocab size: ', counter2)\n",
    "        \n",
    "# Construct gram matrix\n",
    "m2 = torch.zeros(counter3, 226347)\n",
    "print('m2 constructed!')\n",
    "\n",
    "\n",
    "# Need idx2word\n",
    "idx2word = dict([(value, key) for key, value in train_vocab.items()])\n",
    "print('idx2word done!')\n",
    "\n",
    "\n",
    "# Begin correcting gram matrix\n",
    "for sen in test_sentences: \n",
    "    for word in test_sentences[sen].split(): \n",
    "        if word in train_vocab.keys():\n",
    "            m2[sen, train_vocab[word]] = 1\n",
    "print('Gram matrix done')\n",
    "\n",
    "#Note labels\n",
    "test = gzip.open(paths['test'])\n",
    "test_labels = {}\n",
    "counter = 0\n",
    "for line in test:\n",
    "    a = json.loads(line)\n",
    "    if 'reviewText' in a.keys():\n",
    "        if a['sentiment'] == 'positive':\n",
    "            test_labels[counter] = 1\n",
    "        elif a['sentiment'] == 'negative': \n",
    "            test_labels[counter] = 0\n",
    "        counter +=1\n",
    "print('Labels noted!')\n",
    "        \n",
    "#Divide into batches\n",
    "\n",
    "batch_size = 2499\n",
    "num_batches = int(len(m2)/batch_size)\n",
    "test_feats_batches = m2[:batch_size*num_batches].view(num_batches,batch_size, 226347)\n",
    "print('Feature Matrix shapes: ')\n",
    "for feats_batch in test_feats_batches:\n",
    "    print(feats_batch.shape)\n",
    "bingus = list(test_labels.values())\n",
    "bingus = torch.FloatTensor(bingus)\n",
    "num_batches = int(len(bingus)/batch_size)\n",
    "test_label_batches = bingus[:batch_size*num_batches].view(num_batches,batch_size,1)\n",
    "print('label matrix shapes: ')\n",
    "for feats_batch in test_label_batches:\n",
    "    print(feats_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(filepath):\n",
    "    test_vocab = {}\n",
    "    test = gzip.open(filepath)\n",
    "    counter1 = 0\n",
    "    counter2 = 0\n",
    "    counter3 = 0\n",
    "    test_no_reviewText = []\n",
    "    test_labels = {}\n",
    "    test_sentences = {}\n",
    "    for line in test:\n",
    "        counter1 +=1\n",
    "        #print(line)\n",
    "        if 'reviewText' in json.loads(line).keys():\n",
    "            test_sentences[counter3] = json.loads(line)['reviewText']\n",
    "            counter3 += 1\n",
    "            for word in json.loads(line)['reviewText'].split():\n",
    "                if word not in train_vocab.keys():\n",
    "                    test_vocab[word] = counter2\n",
    "                    counter2 += 1\n",
    "        else:\n",
    "            test_no_reviewText.append(counter1)\n",
    "    final_dict = {'line_count' : counter1,\n",
    "                 'review_count' : counter3,\n",
    "                 'vocab_size' : counter2,\n",
    "                 'no_text_reviews' : test_no_reviewText,\n",
    "                 'labels' : test_labels,\n",
    "                 'vocabulary' : test_vocab,\n",
    "                 'sentences' : test_sentences}\n",
    "    return final_dict\n",
    "\n",
    "def construct_gram(vocab, num_sen, vocab_len, sentences): \n",
    "    # Construct gram matrix\n",
    "    m2 = torch.zeros(num_sen, vocab_len)\n",
    "    print('m2 constructed!')\n",
    "    for sen in sentences: \n",
    "        for word in sentences[sen].split(): \n",
    "            m2[sen, vocab[word]] = 1\n",
    "    print('Gram matrix done')\n",
    "    return m2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#model = LogisticRegression()\n",
    "#for feat, label in zip(train_feats_batches,train_label_batches):\n",
    "#    model.fit(feat,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {}\n",
    "counter = 0\n",
    "for batch in test_feats_batches:\n",
    "    preds[counter] = model.predict(batch)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7497,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_arr = []\n",
    "for i in preds:\n",
    "    for j in preds[i]:\n",
    "        new_arr.append(j)\n",
    "len(new_arr)\n",
    "new_arr = np.array(new_arr)\n",
    "new_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.85      0.78       901\n",
      "         1.0       0.91      0.82      0.86      1598\n",
      "\n",
      "    accuracy                           0.83      2499\n",
      "   macro avg       0.82      0.84      0.82      2499\n",
      "weighted avg       0.84      0.83      0.83      2499\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.83      0.77       943\n",
      "         1.0       0.89      0.81      0.85      1556\n",
      "\n",
      "    accuracy                           0.82      2499\n",
      "   macro avg       0.81      0.82      0.81      2499\n",
      "weighted avg       0.83      0.82      0.82      2499\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.86      0.80       991\n",
      "         1.0       0.90      0.81      0.85      1508\n",
      "\n",
      "    accuracy                           0.83      2499\n",
      "   macro avg       0.82      0.83      0.83      2499\n",
      "weighted avg       0.84      0.83      0.83      2499\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.86      0.79       890\n",
      "         1.0       0.91      0.83      0.87      1609\n",
      "\n",
      "    accuracy                           0.84      2499\n",
      "   macro avg       0.82      0.84      0.83      2499\n",
      "weighted avg       0.85      0.84      0.84      2499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pred, true in zip(preds, test_label_batches):\n",
    "    print(classification_report(preds[pred], true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gzip.open(paths['test'])\n",
    "counter = 0\n",
    "new_data = []\n",
    "for i in test:\n",
    "    bingus = json.loads(i)\n",
    "    if new_arr[counter] == 0:\n",
    "        bingus['sentiment'] = 'negative'\n",
    "    elif new_arr[counter] == 1:\n",
    "        bingus['sentiment'] = 'positive'\n",
    "    new_data.append(bingus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verified': True, 'reviewTime': '10 24, 2017', 'reviewerID': 'A2HAJB8L9NVYTZ', 'asin': 'B007Y1AMHE', 'reviewText': 'ok', 'summary': 'ok', 'unixReviewTime': 1508803200, 'sentiment': 'positive', 'id': 0}\n"
     ]
    }
   ],
   "source": [
    "for i in new_data:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"final.json\", 'a') as f:\n",
    "#    for i in new_data:\n",
    "#        json.dump(i,f)\n",
    "#        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Break it down\n",
    "\n",
    "In this part of the project, we are tasked with breaking our own model down, to try and improve it. <br> \n",
    "\n",
    "### Suggested methods: \n",
    "- Change language\n",
    "- More negation\n",
    "- Reviews of other products\n",
    "\n",
    "### Things we should also consider: \n",
    "- Better tokenization\n",
    "- Model tuning\n",
    "- Acutually using development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Look up better regex expression\\n2. Remove stopwords\\n3. implement padding(might have to wait on that one lmao)\\n4. Use a way more sophisticated model. (might wanna wait on that one too)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# better tokenization: \n",
    "'''\n",
    "1. Look up better regex expression\n",
    "2. Remove stopwords\n",
    "3. implement padding(might have to wait on that one lmao)\n",
    "4. Use a way more sophisticated model. (might wanna wait on that one too)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reopen file + imports: \n",
    "import gzip\n",
    "import json\n",
    "import torch \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# This is how they load the data ------------------------------------------\n",
    "#for line in gzip.open('../classification/music_reviews_dev.json.gz'):\n",
    "#    review_data = json.loads(line)\n",
    "#    for key in review_data:\n",
    "#        print('\"' + key +'\": ' + str(review_data[key]))\n",
    "#    break\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "paths = {'train':'../classification/music_reviews_train.json.gz',\n",
    "        'test':'../classification/music_reviews_test_masked.json.gz',\n",
    "        'dev' : '../classification/music_reviews_dev.json.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabs built using TweetTokenizer\n",
    "# \n",
    "\n",
    "\n",
    "def build_vocab(filepath):\n",
    "    train_vocab = {}\n",
    "    train = gzip.open(filepath)\n",
    "    counter1 = 0\n",
    "    counter2 = 0\n",
    "    counter3 = 0\n",
    "    counter = 0\n",
    "    no_reviewText = []\n",
    "    labels = {}\n",
    "    sentences = {}\n",
    "    tokenizer = TweetTokenizer()\n",
    "    for line in train:\n",
    "        counter1 +=1\n",
    "        #print(line)\n",
    "        if 'reviewText' in json.loads(line).keys():\n",
    "            a = json.loads(line)\n",
    "            sentences[counter3] = a['reviewText']\n",
    "            counter3 += 1\n",
    "            if a['sentiment'] == 'positive':\n",
    "                labels[counter] = 1\n",
    "            elif a['sentiment'] == 'negative': \n",
    "                labels[counter] = 0\n",
    "            counter +=1\n",
    "            for word in tokenizer.tokenize(json.loads(line)['reviewText']):\n",
    "                if word not in train_vocab.keys():\n",
    "                    train_vocab[word] = counter2\n",
    "                    counter2 += 1\n",
    "        else:\n",
    "            no_reviewText.append(counter1)\n",
    "    final_dict = {'line_count' : counter1,\n",
    "                 'review_count' : counter3,\n",
    "                 'vocab_size' : counter2,\n",
    "                 'no_text_reviews' : no_reviewText,\n",
    "                 'labels' : labels,\n",
    "                 'vocabulary' : train_vocab,\n",
    "                 'sentences' : sentences}\n",
    "    return final_dict\n",
    "\n",
    "train_set =  build_vocab(paths['train'])\n",
    "dev_set = build_vocab(paths['dev'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might wanna run tests again just to see if the new tokenization improved performance in any way. \n",
    "tokenizer = TweetTokenizer()\n",
    "# unigrams : \n",
    "def create_unigram(vocab, sentences, tokenzier):\n",
    "    # Create matrix\n",
    "    m1 = torch.zeros(len(sentences), len(vocab))\n",
    "    # Correct indices\n",
    "    for sen in range(len(sentences)): \n",
    "        for word in tokenizer.tokenize(sentences[sen]): \n",
    "            if word in vocab.keys():\n",
    "                m1[sen, vocab[word]] = 1\n",
    "    return m1\n",
    "\n",
    "train_unigram = create_unigram(train_set['vocabulary'], train_set['sentences'], tokenizer)\n",
    "\n",
    "def create_batches(matrix, batch_size,labels): \n",
    "    num_batches = int(len(matrix)/batch_size)\n",
    "    feats_batches = matrix[:batch_size*num_batches].view(num_batches,batch_size, matrix.shape[1])\n",
    "    bingus = torch.FloatTensor(list(labels.values()))\n",
    "    num_batches = int(len(bingus)/batch_size)\n",
    "    label_batches = bingus[:batch_size*num_batches].view(num_batches,batch_size,1)\n",
    "    return feats_batches, label_batches\n",
    "train_feat_batches = create_batches(train_unigram, 2499, train_set['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_batches = list(train_feat_batches[1])\n",
    "feat_batches = list(train_feat_batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/christianrasmussen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Make model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train model\n",
    "\n",
    "for feat, label in zip(feat_batches, labels_batches):\n",
    "    model.fit(feat,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_unigram = create_unigram(train_set['vocabulary'], dev_set['sentences'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.87      0.80       900\n",
      "         1.0       0.92      0.83      0.87      1599\n",
      "\n",
      "    accuracy                           0.84      2499\n",
      "   macro avg       0.83      0.85      0.84      2499\n",
      "weighted avg       0.85      0.84      0.85      2499\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.84      0.77       922\n",
      "         1.0       0.90      0.80      0.85      1577\n",
      "\n",
      "    accuracy                           0.82      2499\n",
      "   macro avg       0.81      0.82      0.81      2499\n",
      "weighted avg       0.83      0.82      0.82      2499\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.87      0.81       987\n",
      "         1.0       0.90      0.82      0.86      1512\n",
      "\n",
      "    accuracy                           0.84      2499\n",
      "   macro avg       0.83      0.84      0.83      2499\n",
      "weighted avg       0.84      0.84      0.84      2499\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.86      0.80       909\n",
      "         1.0       0.91      0.84      0.87      1590\n",
      "\n",
      "    accuracy                           0.85      2499\n",
      "   macro avg       0.83      0.85      0.84      2499\n",
      "weighted avg       0.85      0.85      0.85      2499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_batches = create_batches(dev_unigram,2499,dev_set['labels'])\n",
    "preds = {}\n",
    "counter = 0\n",
    "for batch in dev_batches[0]:\n",
    "    preds[counter] = model.predict(batch)\n",
    "    counter+=1\n",
    "new_arr = []\n",
    "for i in preds:\n",
    "    for j in preds[i]:\n",
    "        new_arr.append(j)\n",
    "len(new_arr)\n",
    "new_arr = np.array(new_arr)\n",
    "for pred, true in zip(preds, dev_batches[1]):\n",
    "    print(classification_report(preds[pred], true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_preds = {}\n",
    "counter = 0\n",
    "for batch, pred_dict, true_dict in zip(dev_batches[0], preds.values(), dev_batches[1]):\n",
    "    for sentence, pred, true in zip(batch, pred_dict, true_dict):\n",
    "        if pred != true:\n",
    "            hard_preds[counter] = int(pred)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 2: 1,\n",
       " 7: 1,\n",
       " 8: 1,\n",
       " 9: 0,\n",
       " 10: 1,\n",
       " 25: 0,\n",
       " 32: 1,\n",
       " 37: 0,\n",
       " 48: 0,\n",
       " 49: 1,\n",
       " 58: 1,\n",
       " 62: 0,\n",
       " 64: 0,\n",
       " 71: 0,\n",
       " 78: 1,\n",
       " 79: 1,\n",
       " 87: 1,\n",
       " 88: 1,\n",
       " 91: 1,\n",
       " 93: 1,\n",
       " 95: 1,\n",
       " 108: 1,\n",
       " 109: 1,\n",
       " 123: 1,\n",
       " 131: 0,\n",
       " 132: 1,\n",
       " 133: 0,\n",
       " 136: 1,\n",
       " 143: 1,\n",
       " 147: 1,\n",
       " 150: 1,\n",
       " 153: 0,\n",
       " 162: 0,\n",
       " 176: 1,\n",
       " 187: 0,\n",
       " 189: 0,\n",
       " 196: 0,\n",
       " 206: 0,\n",
       " 216: 1,\n",
       " 222: 1,\n",
       " 224: 0,\n",
       " 226: 0,\n",
       " 230: 1,\n",
       " 239: 1,\n",
       " 241: 1,\n",
       " 243: 0,\n",
       " 249: 1,\n",
       " 261: 1,\n",
       " 276: 1,\n",
       " 285: 1,\n",
       " 289: 0,\n",
       " 293: 1,\n",
       " 297: 1,\n",
       " 308: 0,\n",
       " 312: 1,\n",
       " 316: 1,\n",
       " 317: 1,\n",
       " 320: 1,\n",
       " 324: 0,\n",
       " 339: 1,\n",
       " 352: 0,\n",
       " 358: 1,\n",
       " 360: 1,\n",
       " 363: 1,\n",
       " 385: 0,\n",
       " 391: 1,\n",
       " 394: 1,\n",
       " 401: 0,\n",
       " 408: 1,\n",
       " 419: 1,\n",
       " 424: 1,\n",
       " 445: 1,\n",
       " 447: 1,\n",
       " 454: 1,\n",
       " 456: 1,\n",
       " 459: 1,\n",
       " 460: 0,\n",
       " 465: 1,\n",
       " 486: 1,\n",
       " 499: 1,\n",
       " 501: 1,\n",
       " 516: 0,\n",
       " 517: 0,\n",
       " 532: 1,\n",
       " 546: 1,\n",
       " 551: 1,\n",
       " 559: 0,\n",
       " 565: 0,\n",
       " 572: 1,\n",
       " 595: 0,\n",
       " 598: 1,\n",
       " 604: 1,\n",
       " 607: 1,\n",
       " 611: 1,\n",
       " 612: 1,\n",
       " 616: 1,\n",
       " 625: 0,\n",
       " 629: 1,\n",
       " 632: 1,\n",
       " 647: 0,\n",
       " 651: 1,\n",
       " 654: 0,\n",
       " 657: 1,\n",
       " 659: 1,\n",
       " 661: 1,\n",
       " 666: 1,\n",
       " 683: 0,\n",
       " 686: 1,\n",
       " 689: 0,\n",
       " 693: 1,\n",
       " 697: 0,\n",
       " 699: 1,\n",
       " 706: 0,\n",
       " 718: 1,\n",
       " 726: 0,\n",
       " 732: 1,\n",
       " 752: 1,\n",
       " 753: 1,\n",
       " 760: 1,\n",
       " 775: 1,\n",
       " 782: 1,\n",
       " 783: 0,\n",
       " 787: 1,\n",
       " 797: 1,\n",
       " 798: 1,\n",
       " 799: 1,\n",
       " 809: 1,\n",
       " 811: 1,\n",
       " 816: 1,\n",
       " 819: 1,\n",
       " 821: 1,\n",
       " 825: 1,\n",
       " 840: 1,\n",
       " 842: 1,\n",
       " 849: 1,\n",
       " 851: 0,\n",
       " 858: 1,\n",
       " 863: 0,\n",
       " 869: 1,\n",
       " 877: 1,\n",
       " 888: 0,\n",
       " 900: 0,\n",
       " 910: 1,\n",
       " 917: 0,\n",
       " 929: 1,\n",
       " 942: 0,\n",
       " 951: 1,\n",
       " 953: 1,\n",
       " 967: 1,\n",
       " 970: 1,\n",
       " 973: 1,\n",
       " 974: 0,\n",
       " 976: 0,\n",
       " 988: 0,\n",
       " 995: 1,\n",
       " 999: 1,\n",
       " 1003: 1,\n",
       " 1006: 1,\n",
       " 1013: 1,\n",
       " 1016: 1,\n",
       " 1022: 0,\n",
       " 1024: 0,\n",
       " 1026: 1,\n",
       " 1028: 0,\n",
       " 1032: 1,\n",
       " 1036: 1,\n",
       " 1044: 1,\n",
       " 1046: 1,\n",
       " 1060: 1,\n",
       " 1062: 1,\n",
       " 1072: 0,\n",
       " 1092: 0,\n",
       " 1106: 1,\n",
       " 1109: 0,\n",
       " 1119: 1,\n",
       " 1135: 0,\n",
       " 1138: 1,\n",
       " 1142: 1,\n",
       " 1183: 1,\n",
       " 1184: 1,\n",
       " 1189: 0,\n",
       " 1192: 0,\n",
       " 1200: 1,\n",
       " 1202: 1,\n",
       " 1216: 1,\n",
       " 1220: 0,\n",
       " 1221: 1,\n",
       " 1224: 0,\n",
       " 1225: 0,\n",
       " 1226: 1,\n",
       " 1243: 1,\n",
       " 1247: 0,\n",
       " 1251: 1,\n",
       " 1259: 1,\n",
       " 1263: 0,\n",
       " 1265: 1,\n",
       " 1267: 1,\n",
       " 1270: 0,\n",
       " 1272: 1,\n",
       " 1276: 1,\n",
       " 1282: 1,\n",
       " 1286: 0,\n",
       " 1308: 1,\n",
       " 1309: 0,\n",
       " 1311: 1,\n",
       " 1314: 1,\n",
       " 1321: 1,\n",
       " 1339: 1,\n",
       " 1343: 1,\n",
       " 1345: 0,\n",
       " 1364: 1,\n",
       " 1375: 1,\n",
       " 1390: 1,\n",
       " 1392: 1,\n",
       " 1394: 1,\n",
       " 1395: 1,\n",
       " 1397: 1,\n",
       " 1399: 1,\n",
       " 1402: 1,\n",
       " 1407: 0,\n",
       " 1413: 1,\n",
       " 1419: 1,\n",
       " 1433: 1,\n",
       " 1435: 1,\n",
       " 1449: 1,\n",
       " 1455: 1,\n",
       " 1460: 1,\n",
       " 1470: 1,\n",
       " 1482: 1,\n",
       " 1485: 1,\n",
       " 1486: 1,\n",
       " 1496: 1,\n",
       " 1498: 1,\n",
       " 1499: 1,\n",
       " 1504: 0,\n",
       " 1512: 1,\n",
       " 1513: 0,\n",
       " 1514: 0,\n",
       " 1515: 1,\n",
       " 1519: 1,\n",
       " 1520: 1,\n",
       " 1523: 1,\n",
       " 1534: 0,\n",
       " 1541: 0,\n",
       " 1544: 0,\n",
       " 1551: 1,\n",
       " 1557: 0,\n",
       " 1594: 1,\n",
       " 1597: 1,\n",
       " 1598: 1,\n",
       " 1600: 0,\n",
       " 1601: 1,\n",
       " 1604: 1,\n",
       " 1612: 1,\n",
       " 1630: 1,\n",
       " 1633: 0,\n",
       " 1638: 0,\n",
       " 1653: 1,\n",
       " 1656: 1,\n",
       " 1662: 1,\n",
       " 1671: 0,\n",
       " 1672: 1,\n",
       " 1676: 1,\n",
       " 1690: 1,\n",
       " 1691: 1,\n",
       " 1695: 1,\n",
       " 1705: 1,\n",
       " 1707: 1,\n",
       " 1718: 0,\n",
       " 1720: 1,\n",
       " 1730: 1,\n",
       " 1736: 0,\n",
       " 1739: 0,\n",
       " 1751: 0,\n",
       " 1756: 1,\n",
       " 1758: 1,\n",
       " 1761: 0,\n",
       " 1765: 1,\n",
       " 1776: 1,\n",
       " 1781: 1,\n",
       " 1784: 1,\n",
       " 1785: 1,\n",
       " 1789: 1,\n",
       " 1791: 1,\n",
       " 1801: 0,\n",
       " 1812: 1,\n",
       " 1816: 1,\n",
       " 1830: 0,\n",
       " 1837: 1,\n",
       " 1840: 1,\n",
       " 1841: 0,\n",
       " 1856: 1,\n",
       " 1870: 1,\n",
       " 1871: 1,\n",
       " 1876: 0,\n",
       " 1877: 1,\n",
       " 1907: 1,\n",
       " 1912: 0,\n",
       " 1913: 0,\n",
       " 1919: 1,\n",
       " 1920: 1,\n",
       " 1921: 1,\n",
       " 1928: 1,\n",
       " 1934: 1,\n",
       " 1946: 0,\n",
       " 1950: 0,\n",
       " 1956: 1,\n",
       " 1962: 1,\n",
       " 1967: 1,\n",
       " 1968: 1,\n",
       " 1969: 1,\n",
       " 1978: 1,\n",
       " 1990: 0,\n",
       " 1998: 1,\n",
       " 2000: 1,\n",
       " 2004: 1,\n",
       " 2019: 1,\n",
       " 2029: 0,\n",
       " 2047: 1,\n",
       " 2048: 1,\n",
       " 2052: 1,\n",
       " 2053: 1,\n",
       " 2060: 1,\n",
       " 2063: 0,\n",
       " 2068: 0,\n",
       " 2073: 1,\n",
       " 2074: 1,\n",
       " 2078: 1,\n",
       " 2079: 1,\n",
       " 2081: 0,\n",
       " 2103: 1,\n",
       " 2110: 0,\n",
       " 2114: 1,\n",
       " 2131: 1,\n",
       " 2133: 1,\n",
       " 2146: 1,\n",
       " 2155: 1,\n",
       " 2156: 0,\n",
       " 2164: 0,\n",
       " 2170: 0,\n",
       " 2175: 0,\n",
       " 2176: 1,\n",
       " 2186: 1,\n",
       " 2187: 0,\n",
       " 2192: 0,\n",
       " 2197: 1,\n",
       " 2212: 1,\n",
       " 2215: 1,\n",
       " 2216: 1,\n",
       " 2227: 1,\n",
       " 2235: 0,\n",
       " 2239: 1,\n",
       " 2266: 0,\n",
       " 2271: 0,\n",
       " 2277: 0,\n",
       " 2278: 1,\n",
       " 2285: 1,\n",
       " 2289: 0,\n",
       " 2298: 1,\n",
       " 2299: 1,\n",
       " 2301: 1,\n",
       " 2304: 1,\n",
       " 2311: 0,\n",
       " 2315: 1,\n",
       " 2319: 0,\n",
       " 2324: 1,\n",
       " 2326: 1,\n",
       " 2333: 1,\n",
       " 2340: 1,\n",
       " 2345: 1,\n",
       " 2348: 0,\n",
       " 2351: 0,\n",
       " 2353: 1,\n",
       " 2369: 1,\n",
       " 2374: 1,\n",
       " 2388: 0,\n",
       " 2402: 0,\n",
       " 2406: 0,\n",
       " 2408: 1,\n",
       " 2415: 1,\n",
       " 2430: 1,\n",
       " 2441: 1,\n",
       " 2442: 1,\n",
       " 2449: 1,\n",
       " 2453: 0,\n",
       " 2456: 0,\n",
       " 2457: 1,\n",
       " 2472: 1,\n",
       " 2478: 1,\n",
       " 2482: 0,\n",
       " 2501: 1,\n",
       " 2502: 1,\n",
       " 2503: 1,\n",
       " 2505: 0,\n",
       " 2512: 1,\n",
       " 2513: 1,\n",
       " 2514: 0,\n",
       " 2516: 1,\n",
       " 2519: 1,\n",
       " 2523: 0,\n",
       " 2545: 1,\n",
       " 2546: 0,\n",
       " 2555: 1,\n",
       " 2558: 0,\n",
       " 2559: 1,\n",
       " 2565: 0,\n",
       " 2568: 0,\n",
       " 2569: 1,\n",
       " 2573: 1,\n",
       " 2577: 1,\n",
       " 2579: 0,\n",
       " 2589: 0,\n",
       " 2592: 0,\n",
       " 2604: 1,\n",
       " 2610: 1,\n",
       " 2613: 1,\n",
       " 2623: 1,\n",
       " 2625: 1,\n",
       " 2629: 0,\n",
       " 2634: 1,\n",
       " 2648: 1,\n",
       " 2650: 1,\n",
       " 2651: 1,\n",
       " 2654: 1,\n",
       " 2667: 0,\n",
       " 2670: 1,\n",
       " 2688: 1,\n",
       " 2690: 0,\n",
       " 2704: 0,\n",
       " 2706: 1,\n",
       " 2711: 1,\n",
       " 2712: 1,\n",
       " 2721: 0,\n",
       " 2723: 1,\n",
       " 2728: 1,\n",
       " 2729: 1,\n",
       " 2749: 1,\n",
       " 2753: 1,\n",
       " 2754: 1,\n",
       " 2756: 0,\n",
       " 2757: 0,\n",
       " 2761: 1,\n",
       " 2762: 1,\n",
       " 2767: 0,\n",
       " 2779: 1,\n",
       " 2789: 0,\n",
       " 2794: 0,\n",
       " 2805: 1,\n",
       " 2806: 1,\n",
       " 2807: 1,\n",
       " 2816: 1,\n",
       " 2821: 1,\n",
       " 2833: 0,\n",
       " 2838: 1,\n",
       " 2841: 0,\n",
       " 2847: 0,\n",
       " 2849: 0,\n",
       " 2856: 0,\n",
       " 2857: 0,\n",
       " 2858: 1,\n",
       " 2866: 1,\n",
       " 2878: 1,\n",
       " 2885: 1,\n",
       " 2897: 1,\n",
       " 2898: 1,\n",
       " 2899: 1,\n",
       " 2909: 1,\n",
       " 2911: 1,\n",
       " 2912: 1,\n",
       " 2915: 1,\n",
       " 2917: 1,\n",
       " 2921: 1,\n",
       " 2922: 0,\n",
       " 2925: 1,\n",
       " 2931: 1,\n",
       " 2935: 1,\n",
       " 2937: 0,\n",
       " 2945: 1,\n",
       " 2950: 1,\n",
       " 2953: 1,\n",
       " 2955: 1,\n",
       " 2956: 1,\n",
       " 2957: 1,\n",
       " 2963: 0,\n",
       " 2968: 1,\n",
       " 2972: 1,\n",
       " 2977: 1,\n",
       " 2985: 0,\n",
       " 2990: 0,\n",
       " 2992: 1,\n",
       " 3000: 1,\n",
       " 3008: 1,\n",
       " 3009: 1,\n",
       " 3011: 1,\n",
       " 3016: 1,\n",
       " 3035: 0,\n",
       " 3041: 0,\n",
       " 3042: 1,\n",
       " 3048: 1,\n",
       " 3049: 1,\n",
       " 3051: 1,\n",
       " 3055: 1,\n",
       " 3063: 0,\n",
       " 3072: 0,\n",
       " 3080: 1,\n",
       " 3081: 1,\n",
       " 3085: 0,\n",
       " 3089: 0,\n",
       " 3093: 0,\n",
       " 3100: 0,\n",
       " 3107: 0,\n",
       " 3123: 0,\n",
       " 3127: 1,\n",
       " 3128: 0,\n",
       " 3138: 1,\n",
       " 3141: 1,\n",
       " 3146: 0,\n",
       " 3181: 0,\n",
       " 3184: 1,\n",
       " 3190: 0,\n",
       " 3191: 0,\n",
       " 3193: 1,\n",
       " 3197: 1,\n",
       " 3199: 1,\n",
       " 3200: 1,\n",
       " 3203: 0,\n",
       " 3208: 0,\n",
       " 3222: 1,\n",
       " 3227: 1,\n",
       " 3228: 1,\n",
       " 3234: 1,\n",
       " 3243: 1,\n",
       " 3248: 1,\n",
       " 3249: 1,\n",
       " 3255: 1,\n",
       " 3258: 1,\n",
       " 3262: 1,\n",
       " 3264: 1,\n",
       " 3282: 1,\n",
       " 3290: 1,\n",
       " 3293: 1,\n",
       " 3304: 1,\n",
       " 3317: 1,\n",
       " 3318: 1,\n",
       " 3320: 1,\n",
       " 3327: 0,\n",
       " 3337: 0,\n",
       " 3342: 1,\n",
       " 3344: 0,\n",
       " 3350: 0,\n",
       " 3356: 0,\n",
       " 3378: 1,\n",
       " 3379: 1,\n",
       " 3384: 1,\n",
       " 3387: 1,\n",
       " 3419: 1,\n",
       " 3420: 1,\n",
       " 3421: 1,\n",
       " 3422: 0,\n",
       " 3425: 1,\n",
       " 3435: 1,\n",
       " 3447: 0,\n",
       " 3454: 1,\n",
       " 3460: 1,\n",
       " 3468: 0,\n",
       " 3472: 0,\n",
       " 3488: 1,\n",
       " 3496: 1,\n",
       " 3497: 1,\n",
       " 3498: 0,\n",
       " 3501: 1,\n",
       " 3510: 0,\n",
       " 3512: 1,\n",
       " 3520: 0,\n",
       " 3526: 0,\n",
       " 3552: 0,\n",
       " 3561: 1,\n",
       " 3565: 1,\n",
       " 3569: 0,\n",
       " 3585: 1,\n",
       " 3587: 1,\n",
       " 3600: 0,\n",
       " 3601: 1,\n",
       " 3602: 1,\n",
       " 3603: 0,\n",
       " 3604: 1,\n",
       " 3613: 0,\n",
       " 3614: 0,\n",
       " 3618: 0,\n",
       " 3623: 1,\n",
       " 3638: 1,\n",
       " 3639: 1,\n",
       " 3646: 1,\n",
       " 3647: 1,\n",
       " 3648: 1,\n",
       " 3649: 1,\n",
       " 3653: 0,\n",
       " 3668: 1,\n",
       " 3672: 1,\n",
       " 3679: 0,\n",
       " 3686: 1,\n",
       " 3689: 1,\n",
       " 3692: 0,\n",
       " 3694: 1,\n",
       " 3702: 1,\n",
       " 3705: 1,\n",
       " 3706: 1,\n",
       " 3707: 0,\n",
       " 3719: 1,\n",
       " 3723: 0,\n",
       " 3727: 1,\n",
       " 3730: 1,\n",
       " 3731: 1,\n",
       " 3737: 0,\n",
       " 3741: 1,\n",
       " 3743: 1,\n",
       " 3744: 1,\n",
       " 3749: 1,\n",
       " 3750: 1,\n",
       " 3753: 1,\n",
       " 3755: 0,\n",
       " 3763: 1,\n",
       " 3765: 1,\n",
       " 3779: 0,\n",
       " 3785: 0,\n",
       " 3787: 1,\n",
       " 3793: 1,\n",
       " 3800: 0,\n",
       " 3805: 1,\n",
       " 3813: 1,\n",
       " 3822: 0,\n",
       " 3823: 1,\n",
       " 3839: 0,\n",
       " 3840: 1,\n",
       " 3846: 1,\n",
       " 3848: 1,\n",
       " 3854: 1,\n",
       " 3855: 1,\n",
       " 3857: 0,\n",
       " 3860: 0,\n",
       " 3862: 0,\n",
       " 3870: 1,\n",
       " 3873: 1,\n",
       " 3882: 0,\n",
       " 3884: 1,\n",
       " 3888: 1,\n",
       " 3895: 1,\n",
       " 3898: 1,\n",
       " 3899: 0,\n",
       " 3907: 0,\n",
       " 3914: 1,\n",
       " 3921: 1,\n",
       " 3924: 0,\n",
       " 3925: 1,\n",
       " 3926: 1,\n",
       " 3927: 0,\n",
       " 3941: 1,\n",
       " 3944: 1,\n",
       " 3945: 0,\n",
       " 3950: 1,\n",
       " 3952: 1,\n",
       " 3958: 1,\n",
       " 3960: 1,\n",
       " 3965: 0,\n",
       " 3969: 1,\n",
       " 3973: 1,\n",
       " 3977: 1,\n",
       " 3993: 1,\n",
       " 3997: 1,\n",
       " 4000: 1,\n",
       " 4004: 1,\n",
       " 4008: 1,\n",
       " 4020: 1,\n",
       " 4021: 1,\n",
       " 4033: 1,\n",
       " 4038: 1,\n",
       " 4042: 0,\n",
       " 4057: 1,\n",
       " 4060: 0,\n",
       " 4062: 0,\n",
       " 4073: 0,\n",
       " 4079: 1,\n",
       " 4089: 1,\n",
       " 4090: 0,\n",
       " 4093: 0,\n",
       " 4096: 1,\n",
       " 4100: 0,\n",
       " 4106: 1,\n",
       " 4118: 0,\n",
       " 4120: 1,\n",
       " 4124: 1,\n",
       " 4128: 1,\n",
       " 4130: 0,\n",
       " 4131: 0,\n",
       " 4136: 0,\n",
       " 4140: 1,\n",
       " 4142: 1,\n",
       " 4152: 1,\n",
       " 4158: 0,\n",
       " 4163: 1,\n",
       " 4191: 1,\n",
       " 4202: 1,\n",
       " 4209: 1,\n",
       " 4223: 1,\n",
       " 4225: 1,\n",
       " 4228: 1,\n",
       " 4236: 0,\n",
       " 4241: 1,\n",
       " 4245: 0,\n",
       " 4252: 1,\n",
       " 4253: 0,\n",
       " 4254: 1,\n",
       " 4256: 1,\n",
       " 4259: 0,\n",
       " 4264: 0,\n",
       " 4268: 1,\n",
       " 4277: 1,\n",
       " 4281: 0,\n",
       " 4283: 1,\n",
       " 4286: 1,\n",
       " 4290: 1,\n",
       " 4296: 1,\n",
       " 4304: 1,\n",
       " 4310: 1,\n",
       " 4323: 0,\n",
       " 4325: 1,\n",
       " 4333: 1,\n",
       " 4337: 1,\n",
       " 4340: 1,\n",
       " 4344: 1,\n",
       " 4346: 1,\n",
       " 4347: 1,\n",
       " 4355: 1,\n",
       " 4358: 0,\n",
       " 4359: 0,\n",
       " 4363: 1,\n",
       " 4373: 0,\n",
       " 4382: 1,\n",
       " 4386: 1,\n",
       " 4387: 1,\n",
       " 4393: 0,\n",
       " 4397: 0,\n",
       " 4405: 1,\n",
       " 4409: 0,\n",
       " 4414: 1,\n",
       " 4417: 1,\n",
       " 4429: 1,\n",
       " 4435: 0,\n",
       " 4440: 1,\n",
       " 4446: 0,\n",
       " 4454: 1,\n",
       " 4459: 1,\n",
       " 4463: 1,\n",
       " 4476: 1,\n",
       " 4481: 0,\n",
       " 4486: 1,\n",
       " 4489: 1,\n",
       " 4492: 1,\n",
       " 4495: 0,\n",
       " 4503: 1,\n",
       " 4508: 1,\n",
       " 4511: 1,\n",
       " 4517: 0,\n",
       " 4522: 0,\n",
       " 4534: 1,\n",
       " 4537: 1,\n",
       " 4539: 1,\n",
       " 4543: 1,\n",
       " 4546: 1,\n",
       " 4556: 1,\n",
       " 4562: 1,\n",
       " 4566: 0,\n",
       " 4569: 1,\n",
       " 4580: 1,\n",
       " 4586: 0,\n",
       " 4589: 1,\n",
       " 4591: 1,\n",
       " 4605: 1,\n",
       " 4609: 1,\n",
       " 4610: 1,\n",
       " 4614: 0,\n",
       " 4617: 1,\n",
       " 4619: 1,\n",
       " 4620: 1,\n",
       " 4621: 1,\n",
       " 4624: 0,\n",
       " 4626: 1,\n",
       " 4628: 0,\n",
       " 4629: 0,\n",
       " 4642: 1,\n",
       " 4645: 1,\n",
       " 4648: 1,\n",
       " 4651: 1,\n",
       " 4661: 1,\n",
       " 4662: 0,\n",
       " 4667: 1,\n",
       " 4668: 0,\n",
       " 4684: 1,\n",
       " 4687: 1,\n",
       " 4691: 0,\n",
       " 4693: 1,\n",
       " 4695: 1,\n",
       " 4698: 1,\n",
       " 4704: 0,\n",
       " 4714: 1,\n",
       " 4728: 1,\n",
       " 4730: 1,\n",
       " 4735: 0,\n",
       " 4736: 0,\n",
       " 4739: 1,\n",
       " 4757: 0,\n",
       " 4770: 0,\n",
       " 4772: 1,\n",
       " 4774: 1,\n",
       " 4782: 1,\n",
       " 4784: 1,\n",
       " 4786: 1,\n",
       " 4797: 1,\n",
       " 4798: 1,\n",
       " 4806: 0,\n",
       " 4813: 0,\n",
       " 4814: 0,\n",
       " 4816: 0,\n",
       " 4817: 1,\n",
       " 4835: 0,\n",
       " 4841: 1,\n",
       " 4842: 1,\n",
       " 4846: 0,\n",
       " 4860: 0,\n",
       " 4874: 1,\n",
       " 4878: 1,\n",
       " 4879: 1,\n",
       " 4889: 1,\n",
       " 4904: 1,\n",
       " 4908: 1,\n",
       " 4909: 0,\n",
       " 4912: 1,\n",
       " 4935: 0,\n",
       " 4944: 1,\n",
       " 4948: 1,\n",
       " 4949: 1,\n",
       " 4950: 1,\n",
       " 4962: 1,\n",
       " 4973: 1,\n",
       " 4982: 1,\n",
       " 5001: 1,\n",
       " 5010: 0,\n",
       " 5016: 1,\n",
       " 5019: 1,\n",
       " 5030: 1,\n",
       " 5032: 0,\n",
       " 5033: 1,\n",
       " 5040: 0,\n",
       " 5042: 1,\n",
       " 5050: 1,\n",
       " 5052: 1,\n",
       " 5054: 0,\n",
       " 5058: 1,\n",
       " 5062: 0,\n",
       " 5067: 1,\n",
       " 5074: 0,\n",
       " 5080: 1,\n",
       " 5082: 0,\n",
       " 5084: 1,\n",
       " 5087: 0,\n",
       " 5092: 0,\n",
       " 5099: 1,\n",
       " 5100: 0,\n",
       " 5109: 1,\n",
       " 5111: 0,\n",
       " 5118: 1,\n",
       " 5122: 0,\n",
       " 5127: 1,\n",
       " 5137: 1,\n",
       " 5138: 1,\n",
       " 5141: 0,\n",
       " 5147: 0,\n",
       " 5158: 1,\n",
       " 5159: 1,\n",
       " 5166: 0,\n",
       " 5176: 0,\n",
       " 5177: 1,\n",
       " 5178: 1,\n",
       " 5182: 1,\n",
       " 5184: 0,\n",
       " 5190: 1,\n",
       " 5200: 1,\n",
       " 5203: 1,\n",
       " 5205: 1,\n",
       " 5208: 1,\n",
       " 5215: 1,\n",
       " 5217: 1,\n",
       " 5219: 1,\n",
       " 5226: 1,\n",
       " 5228: 1,\n",
       " 5235: 1,\n",
       " 5236: 0,\n",
       " 5239: 0,\n",
       " 5242: 1,\n",
       " 5246: 1,\n",
       " 5256: 0,\n",
       " 5258: 1,\n",
       " 5269: 0,\n",
       " 5271: 0,\n",
       " 5274: 1,\n",
       " 5275: 1,\n",
       " 5277: 0,\n",
       " 5279: 0,\n",
       " 5282: 1,\n",
       " 5286: 0,\n",
       " 5293: 0,\n",
       " 5298: 1,\n",
       " 5305: 1,\n",
       " 5311: 1,\n",
       " 5316: 1,\n",
       " 5318: 0,\n",
       " 5319: 0,\n",
       " 5326: 1,\n",
       " 5329: 0,\n",
       " 5331: 1,\n",
       " 5336: 1,\n",
       " 5341: 0,\n",
       " 5343: 0,\n",
       " 5345: 1,\n",
       " 5349: 1,\n",
       " 5357: 1,\n",
       " 5367: 1,\n",
       " 5374: 1,\n",
       " 5380: 1,\n",
       " 5383: 1,\n",
       " 5385: 1,\n",
       " 5393: 1,\n",
       " 5403: 1,\n",
       " 5404: 1,\n",
       " 5405: 1,\n",
       " 5407: 1,\n",
       " 5415: 1,\n",
       " 5416: 1,\n",
       " 5423: 1,\n",
       " 5429: 1,\n",
       " 5437: 1,\n",
       " 5438: 0,\n",
       " 5453: 1,\n",
       " 5454: 0,\n",
       " 5457: 1,\n",
       " 5458: 1,\n",
       " 5460: 1,\n",
       " 5469: 0,\n",
       " 5486: 1,\n",
       " 5488: 1,\n",
       " 5490: 1,\n",
       " 5497: 0,\n",
       " 5499: 1,\n",
       " 5502: 0,\n",
       " 5507: 0,\n",
       " 5508: 0,\n",
       " 5519: 1,\n",
       " 5526: 1,\n",
       " 5535: 0,\n",
       " 5546: 1,\n",
       " 5548: 1,\n",
       " 5550: 1,\n",
       " 5568: 1,\n",
       " 5569: 1,\n",
       " 5571: 1,\n",
       " 5573: 1,\n",
       " 5575: 1,\n",
       " 5582: 1,\n",
       " 5587: 1,\n",
       " 5599: 1,\n",
       " 5601: 1,\n",
       " 5606: 1,\n",
       " 5637: 0,\n",
       " 5643: 1,\n",
       " 5648: 1,\n",
       " 5655: 1,\n",
       " 5658: 1,\n",
       " 5659: 1,\n",
       " 5660: 1,\n",
       " 5671: 1,\n",
       " 5678: 1,\n",
       " 5686: 0,\n",
       " 5696: 1,\n",
       " 5698: 0,\n",
       " 5700: 0,\n",
       " 5702: 0,\n",
       " 5703: 0,\n",
       " 5704: 1,\n",
       " 5711: 0,\n",
       " 5713: 1,\n",
       " 5714: 1,\n",
       " 5728: 1,\n",
       " 5737: 0,\n",
       " 5749: 0,\n",
       " 5751: 1,\n",
       " 5756: 0,\n",
       " 5757: 1,\n",
       " 5775: 1,\n",
       " 5778: 0,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing the first 200 misclassification sentences\n",
    "hard_sens = []\n",
    "for i in hard_preds:\n",
    "    hard_sentence = train_set['sentences'][i]\n",
    "    if len(hard_sens) >= 200:\n",
    "        break\n",
    "    else:\n",
    "        hard_sens.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gzip.open(paths['dev'])\n",
    "new_data = []\n",
    "counter = 0\n",
    "for i in test:\n",
    "    bingus = json.loads(i)\n",
    "    if counter in hard_sens:\n",
    "        new_data.append(bingus)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hard_cases.json\", 'a') as f:\n",
    "    for i in new_data:\n",
    "        json.dump(i,f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-14-7d73b51de4c3>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-7d73b51de4c3>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checklist section:\n",
    "Gonna follow how they do in the official documentation.\n",
    "Pretty dumb donkey way of doing this. But hope it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the same stuff that they do in the doc. \n",
    "import checklist.editor\n",
    "import checklist.text_generation\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "import numpy as np\n",
    "import spacy\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.perturb import Perturb\n",
    "from spacy.lang.en.examples import sentences \n",
    "import random \n",
    "# Load editor. \n",
    "\n",
    "editor = checklist.editor.Editor()\n",
    "editor.tg\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sentences = dev_set['sentences'].values()\n",
    "parsed_data = list(nlp.pipe(sentences))\n",
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My dentist recommended this as a relaxation technique for dental visits. They give me an ipod with headphones, play this on it and it relieves some of the stress of dental treatment, which I dislike intensely.\n",
       "It worked so well that I bought my own copy to try at home. I fall asleep after a couple of minutes and stay asleep. Instead of tossing and turning, I hardly move at all. Highly recommend."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing collection of music_nouns\n",
    "music_noun = ['project', 'artist', 'album', 'genre', 'compilation', 'ep', 'singer', 'band', 'guitar', 'drummer', 'guitarist']\n",
    "editor.add_lexicon('music_noun', music_noun, overwrite=True)\n",
    "\n",
    "# Negations\n",
    "\n",
    "negations = ['don\\'t', 'can\\'t' , 'not', 'won\\'t', 'nothing']\n",
    "past_negations = ['didn\\'t', 'wouldn\\'t', 'couldn\\'t', 'shouldn\\'t']\n",
    "editor.add_lexicon('negation', negations, overwrite=True)\n",
    "editor.add_lexicon('past_negation', past_negations, overwrite=True)\n",
    "\n",
    "# Post / neg adj \n",
    "pos_adj = ['good', 'great', 'excellent', 'amazing', 'extraordinary', 'beautiful', 'fantastic', 'nice', 'incredible', 'exceptional', 'awesome', 'perfect', 'fun', 'happy', 'adorable', 'brilliant', 'exciting', 'sweet', 'wonderful']\n",
    "neg_adj = ['awful', 'bad', 'horrible', 'weird', 'rough', 'lousy', 'unhappy', 'average', 'difficult', 'poor', 'sad', 'frustrating', 'hard', 'lame', 'nasty', 'annoying', 'boring', 'creepy', 'dreadful', 'ridiculous', 'terrible', 'ugly', 'unpleasant']\n",
    "editor.add_lexicon('pos_adj', pos_adj, overwrite=True)\n",
    "editor.add_lexicon('neg_adj', neg_adj, overwrite=True)\n",
    "\n",
    "# Bunch of other shit \n",
    "\n",
    "pos_verb_present = ['like', 'enjoy', 'appreciate', 'love',  'recommend', 'admire', 'value', 'welcome']\n",
    "neg_verb_present = ['hate', 'dislike', 'regret',  'abhor', 'dread', 'despise' ]\n",
    "neutral_verb_present = ['see', 'find']\n",
    "pos_verb_past = ['liked', 'enjoyed', 'appreciated', 'loved', 'admired', 'valued', 'welcomed']\n",
    "neg_verb_past = ['hated', 'disliked', 'regretted',  'abhorred', 'dreaded', 'despised']\n",
    "neutral_verb_past = ['saw', 'found']\n",
    "editor.add_lexicon('pos_verb_present', pos_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_present', neg_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_present', neutral_verb_present, overwrite=True)\n",
    "editor.add_lexicon('pos_verb_past', pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_past', neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_past', neutral_verb_past, overwrite=True)\n",
    "editor.add_lexicon('pos_verb', pos_verb_present+ pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb', neg_verb_present + neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb', neutral_verb_present + neutral_verb_past, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_1 = list(editor.template('I {negation} {pos_verb_present} the {music_noun}')['data'])\n",
    "sen_2 = list(editor.template('I {past_negation} {neg_verb_present} the really {neg_adj} {music_noun}')['data'])\n",
    "irony_1 = list(editor.template('No the {neg_adj} {music_noun}, was totally {pos_adj} yeah...')['data'])\n",
    "negation_3 = list(editor.template('I actually {past_negation} {neg_verb_present} the {music_noun}')['data'])\n",
    "negation_4 = list(editor.template('Contrary to what i thought, the {music_noun}, wasn\\'t {neg_adj}')['data'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_1 = random.sample(sen_1, 15)\n",
    "samples_2 = random.sample(sen_2, 15)\n",
    "samples_3 = random.sample(irony_1, 15)\n",
    "samples_4 = random.sample(negation_3, 15)\n",
    "samples_5 = random.sample(negation_4, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I actually didn't hate the artist\",\n",
       " \"I actually wouldn't despise the album\",\n",
       " \"I actually wouldn't dread the guitarist\",\n",
       " \"I actually shouldn't hate the ep\",\n",
       " \"I actually didn't dread the genre\",\n",
       " \"I actually wouldn't dread the compilation\",\n",
       " \"I actually wouldn't abhor the artist\",\n",
       " \"I actually couldn't hate the guitar\",\n",
       " \"I actually didn't despise the genre\",\n",
       " \"I actually wouldn't abhor the genre\",\n",
       " \"I actually shouldn't dislike the ep\",\n",
       " \"I actually couldn't dread the guitarist\",\n",
       " \"I actually shouldn't dislike the guitarist\",\n",
       " \"I actually couldn't abhor the compilation\",\n",
       " \"I actually wouldn't despise the ep\"]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
