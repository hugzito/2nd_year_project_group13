{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project phase 1: Baseline\n",
    "\n",
    "The goal of this phase is to create a baseline model. Note that the word baseline can mean different things. In the course we distinguished three different types of baselines:\n",
    "* 1. The simplest possible approach (majority baseline, i.e. everything is positive or noun)\n",
    "* 2. A simple machine learning classifier (logistic regression with words as features)\n",
    "* 3. The ``state-of-the-art'' approach on which you want to improve (your starting point)\n",
    "\n",
    "For this phase you need to make a number 2 or 3 baseline. \n",
    "\n",
    "If you plan to have a research question like: can we improve sentiment detection systems by doing X, the answer to the question is the most relevant if you have a competetive baseline (3). In this case we would suggest to use a BiLSTM or even a transformer based model, so that you can re-use the baseline for the final research question (phase 3).\n",
    "\n",
    "You should pick one of the following tasks to create your baseline for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Sentiment classification\n",
    "* The data can be found in the `classification` folder.\n",
    "* The goal is to predict the label in the `sentiment` field.\n",
    "* **You have to upload the predictions of `music_reviews_test_masked.json.gz` to CodaLab. (The link will be posted here on monday). Note that the format should match the json files in the repository.**\n",
    "* **Also upload a .txt file on LearnIt (one per group) with a short description of your baseline.**\n",
    "\n",
    "The data can be read like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "for line in gzip.open('classification/music_reviews_dev.json.gz'):\n",
    "    review_data = json.loads(line)\n",
    "    for key in review_data:\n",
    "        print('\"' + key +'\": ' + str(review_data[key]))\n",
    "    break\n",
    "paths = {'train':'classification/music_reviews_train.json.gz',\n",
    "        'test':'classification/music_reviews_test_masked.json.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = {}\n",
    "train = gzip.open(paths['train'])\n",
    "counter1 = 0\n",
    "counter2 = 0\n",
    "counter3 = 0\n",
    "train_no_reviewText = []\n",
    "labels = {}\n",
    "train_sentences = {}\n",
    "for line in train:\n",
    "    counter1 +=1\n",
    "    #print(line)\n",
    "    if 'reviewText' in json.loads(line).keys():\n",
    "        train_sentences[counter3] = json.loads(line)['reviewText']\n",
    "        counter3 += 1\n",
    "        for word in json.loads(line)['reviewText'].split():\n",
    "            if word not in train_vocab.keys():\n",
    "                train_vocab[word] = counter2\n",
    "                counter2 += 1\n",
    "    else:\n",
    "        train_no_reviewText.append(counter1)\n",
    "print(counter3,counter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gram matrix \n",
    "m1 = torch.zeros(counter3, counter2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need idx2word\n",
    "idx2word = dict([(value, key) for key, value in train_vocab.items()])\n",
    "\n",
    "# Begin correcting gram matrix\n",
    "\n",
    "for sen in train_sentences: \n",
    "    for word in train_sentences[sen].split(): \n",
    "        m1[sen, train_vocab[word]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = {}\n",
    "train = gzip.open(paths['train'])\n",
    "train_labels = {}\n",
    "counter = 0\n",
    "for line in train:\n",
    "    a = json.loads(line)\n",
    "    if 'reviewText' in a.keys():\n",
    "        if a['sentiment'] == 'positive':\n",
    "            train_labels[counter] = 1\n",
    "        elif a['sentiment'] == 'negative': \n",
    "            train_labels[counter] = 0\n",
    "        counter +=1\n",
    "\n",
    "        \n",
    "#len(labels)\n",
    "#print(type(labels))\n",
    "\n",
    "\n",
    "\n",
    "counter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "num_batches = int(len(m1)/batch_size)\n",
    "train_feats_batches = m1[:batch_size*num_batches].view(num_batches,batch_size, counter2)\n",
    "for feats_batch in train_feats_batches:\n",
    "    print(feats_batch.shape)\n",
    "\n",
    "bingus = list(train_labels.values())\n",
    "bingus = torch.FloatTensor(bingus)\n",
    "\n",
    "num_batches = int(len(bingus)/batch_size)\n",
    "train_label_batches = bingus[:batch_size*num_batches].view(num_batches,batch_size,1)\n",
    "counter = 1\n",
    "for feats_batch in train_label_batches:\n",
    "    counter+=1\n",
    "    print(feats_batch.shape)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode test labels\n",
    "test_vocab = {}\n",
    "test = gzip.open(paths['test'])\n",
    "counter1 = 0\n",
    "counter2 = 0\n",
    "counter3 = 0\n",
    "test_no_reviewText = []\n",
    "test_labels = {}\n",
    "test_sentences = {}\n",
    "for line in test:\n",
    "    counter1 +=1\n",
    "    #print(line)\n",
    "    if 'reviewText' in json.loads(line).keys():\n",
    "        test_sentences[counter3] = json.loads(line)['reviewText']\n",
    "        counter3 += 1\n",
    "        for word in json.loads(line)['reviewText'].split():\n",
    "            if word not in train_vocab.keys():\n",
    "                test_vocab[word] = counter2\n",
    "                counter2 += 1\n",
    "    else:\n",
    "        test_no_reviewText.append(counter1)\n",
    "print('Vocab size: ', counter2)\n",
    "        \n",
    "# Construct gram matrix\n",
    "m2 = torch.zeros(counter3, 226347)\n",
    "print('m2 constructed!')\n",
    "\n",
    "\n",
    "# Need idx2word\n",
    "idx2word = dict([(value, key) for key, value in train_vocab.items()])\n",
    "print('idx2word done!')\n",
    "\n",
    "\n",
    "# Begin correcting gram matrix\n",
    "for sen in test_sentences: \n",
    "    for word in test_sentences[sen].split(): \n",
    "        if word in train_vocab.keys():\n",
    "            m2[sen, train_vocab[word]] = 1\n",
    "print('Gram matrix done')\n",
    "\n",
    "#Note labels\n",
    "test = gzip.open(paths['test'])\n",
    "test_labels = {}\n",
    "counter = 0\n",
    "for line in test:\n",
    "    a = json.loads(line)\n",
    "    if 'reviewText' in a.keys():\n",
    "        if a['sentiment'] == 'positive':\n",
    "            test_labels[counter] = 1\n",
    "        elif a['sentiment'] == 'negative': \n",
    "            test_labels[counter] = 0\n",
    "        counter +=1\n",
    "print('Labels noted!')\n",
    "        \n",
    "#Divide into batches\n",
    "\n",
    "batch_size = 2499\n",
    "num_batches = int(len(m2)/batch_size)\n",
    "test_feats_batches = m2[:batch_size*num_batches].view(num_batches,batch_size, 226347)\n",
    "print('Feature Matrix shapes: ')\n",
    "for feats_batch in test_feats_batches:\n",
    "    print(feats_batch.shape)\n",
    "bingus = list(test_labels.values())\n",
    "bingus = torch.FloatTensor(bingus)\n",
    "num_batches = int(len(bingus)/batch_size)\n",
    "test_label_batches = bingus[:batch_size*num_batches].view(num_batches,batch_size,1)\n",
    "print('label matrix shapes: ')\n",
    "for feats_batch in test_label_batches:\n",
    "    print(feats_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(filepath):\n",
    "    test_vocab = {}\n",
    "    test = gzip.open(filepath)\n",
    "    counter1 = 0\n",
    "    counter2 = 0\n",
    "    counter3 = 0\n",
    "    test_no_reviewText = []\n",
    "    test_labels = {}\n",
    "    test_sentences = {}\n",
    "    for line in test:\n",
    "        counter1 +=1\n",
    "        #print(line)\n",
    "        if 'reviewText' in json.loads(line).keys():\n",
    "            test_sentences[counter3] = json.loads(line)['reviewText']\n",
    "            counter3 += 1\n",
    "            for word in json.loads(line)['reviewText'].split():\n",
    "                if word not in train_vocab.keys():\n",
    "                    test_vocab[word] = counter2\n",
    "                    counter2 += 1\n",
    "        else:\n",
    "            test_no_reviewText.append(counter1)\n",
    "    final_dict = {'line_count' : counter1,\n",
    "                 'review_count' : counter3,\n",
    "                 'vocab_size' : counter2,\n",
    "                 'no_text_reviews' : test_no_reviewText,\n",
    "                 'labels' : test_labels,\n",
    "                 'vocabulary' : test_vocab,\n",
    "                 'sentences' : test_sentences}\n",
    "    return final_dict\n",
    "\n",
    "def construct_gram(vocab, num_sen, vocab_len, sentences): \n",
    "    # Construct gram matrix\n",
    "    m2 = torch.zeros(num_sen, vocab_len)\n",
    "    print('m2 constructed!')\n",
    "    for sen in sentences: \n",
    "        for word in sentences[sen].split(): \n",
    "            m2[sen, vocab[word]] = 1\n",
    "    print('Gram matrix done')\n",
    "    return m2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = LogisticRegression()\n",
    "#for feat, label in zip(train_feats_batches,train_label_batches):\n",
    "#    model.fit(feat,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {}\n",
    "counter = 0\n",
    "for batch in test_feats_batches:\n",
    "    preds[counter] = model.predict(batch)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr = []\n",
    "for i in preds:\n",
    "    for j in preds[i]:\n",
    "        new_arr.append(j)\n",
    "len(new_arr)\n",
    "new_arr = np.array(new_arr)\n",
    "new_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred, true in zip(preds, test_label_batches):\n",
    "    print(classification_report(preds[pred], true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gzip.open(paths['test'])\n",
    "counter = 0\n",
    "new_data = []\n",
    "for i in test:\n",
    "    bingus = json.loads(i)\n",
    "    if new_arr[counter] == 0:\n",
    "        bingus['sentiment'] = 'negative'\n",
    "    elif new_arr[counter] == 1:\n",
    "        bingus['sentiment'] = 'positive'\n",
    "    new_data.append(bingus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new_data:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"final.json\", 'a') as f:\n",
    "#    for i in new_data:\n",
    "#        json.dump(i,f)\n",
    "#        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Break it down\n",
    "\n",
    "In this part of the project, we are tasked with breaking our own model down, to try and improve it. <br> \n",
    "\n",
    "### Suggested methods: \n",
    "- Change language\n",
    "- More negation\n",
    "- Reviews of other products\n",
    "\n",
    "### Things we should also consider: \n",
    "- Better tokenization\n",
    "- Model tuning\n",
    "- Acutually using development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better tokenization: \n",
    "'''\n",
    "1. Look up better regex expression\n",
    "2. Remove stopwords\n",
    "3. implement padding(might have to wait on that one lmao)\n",
    "4. Use a way more sophisticated model. (might wanna wait on that one too)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reopen file + imports: \n",
    "import gzip\n",
    "import json\n",
    "import torch \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# This is how they load the data ------------------------------------------\n",
    "#for line in gzip.open('../classification/music_reviews_dev.json.gz'):\n",
    "#    review_data = json.loads(line)\n",
    "#    for key in review_data:\n",
    "#        print('\"' + key +'\": ' + str(review_data[key]))\n",
    "#    break\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "paths = {'train':'../classification/music_reviews_train.json.gz',\n",
    "        'test':'../classification/music_reviews_test_masked.json.gz',\n",
    "        'dev' : '../classification/music_reviews_dev.json.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabs built using TweetTokenizer\n",
    "# \n",
    "\n",
    "\n",
    "def build_vocab(filepath):\n",
    "    train_vocab = {}\n",
    "    train = gzip.open(filepath)\n",
    "    counter1 = 0\n",
    "    counter2 = 0\n",
    "    counter3 = 0\n",
    "    counter = 0\n",
    "    no_reviewText = []\n",
    "    labels = {}\n",
    "    sentences = {}\n",
    "    tokenizer = TweetTokenizer()\n",
    "    for line in train:\n",
    "        counter1 +=1\n",
    "        #print(line)\n",
    "        if 'reviewText' in json.loads(line).keys():\n",
    "            a = json.loads(line)\n",
    "            sentences[counter3] = a['reviewText']\n",
    "            counter3 += 1\n",
    "            if a['sentiment'] == 'positive':\n",
    "                labels[counter] = 1\n",
    "            elif a['sentiment'] == 'negative': \n",
    "                labels[counter] = 0\n",
    "            counter +=1\n",
    "            for word in tokenizer.tokenize(json.loads(line)['reviewText']):\n",
    "                if word not in train_vocab.keys():\n",
    "                    train_vocab[word] = counter2\n",
    "                    counter2 += 1\n",
    "        else:\n",
    "            no_reviewText.append(counter1)\n",
    "    final_dict = {'line_count' : counter1,\n",
    "                 'review_count' : counter3,\n",
    "                 'vocab_size' : counter2,\n",
    "                 'no_text_reviews' : no_reviewText,\n",
    "                 'labels' : labels,\n",
    "                 'vocabulary' : train_vocab,\n",
    "                 'sentences' : sentences}\n",
    "    return final_dict\n",
    "\n",
    "train_set =  build_vocab(paths['train'])\n",
    "dev_set = build_vocab(paths['dev'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might wanna run tests again just to see if the new tokenization improved performance in any way. \n",
    "tokenizer = TweetTokenizer()\n",
    "# unigrams : \n",
    "def create_unigram(vocab, sentences, tokenzier):\n",
    "    # Create matrix\n",
    "    m1 = torch.zeros(len(sentences), len(vocab))\n",
    "    # Correct indices\n",
    "    for sen in range(len(sentences)): \n",
    "        for word in tokenizer.tokenize(sentences[sen]): \n",
    "            if word in vocab.keys():\n",
    "                m1[sen, vocab[word]] = 1\n",
    "    return m1\n",
    "\n",
    "train_unigram = create_unigram(train_set['vocabulary'], train_set['sentences'], tokenizer)\n",
    "\n",
    "def create_batches(matrix, batch_size,labels): \n",
    "    num_batches = int(len(matrix)/batch_size)\n",
    "    feats_batches = matrix[:batch_size*num_batches].view(num_batches,batch_size, matrix.shape[1])\n",
    "    bingus = torch.FloatTensor(list(labels.values()))\n",
    "    num_batches = int(len(bingus)/batch_size)\n",
    "    label_batches = bingus[:batch_size*num_batches].view(num_batches,batch_size,1)\n",
    "    return feats_batches, label_batches\n",
    "train_feat_batches = create_batches(train_unigram, 2499, train_set['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_batches = list(train_feat_batches[1])\n",
    "feat_batches = list(train_feat_batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train model\n",
    "\n",
    "for feat, label in zip(feat_batches, labels_batches):\n",
    "    model.fit(feat,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_unigram = create_unigram(train_set['vocabulary'], dev_set['sentences'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_batches = create_batches(dev_unigram,2499,dev_set['labels'])\n",
    "preds = {}\n",
    "counter = 0\n",
    "for batch in dev_batches[0]:\n",
    "    preds[counter] = model.predict(batch)\n",
    "    counter+=1\n",
    "new_arr = []\n",
    "for i in preds:\n",
    "    for j in preds[i]:\n",
    "        new_arr.append(j)\n",
    "len(new_arr)\n",
    "new_arr = np.array(new_arr)\n",
    "for pred, true in zip(preds, dev_batches[1]):\n",
    "    print(classification_report(preds[pred], true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_preds = {}\n",
    "counter = 0\n",
    "for batch, pred_dict, true_dict in zip(dev_batches[0], preds.values(), dev_batches[1]):\n",
    "    for sentence, pred, true in zip(batch, pred_dict, true_dict):\n",
    "        if pred != true:\n",
    "            hard_preds[counter] = int(pred)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing the first 200 misclassification sentences\n",
    "hard_sens = []\n",
    "for i in hard_preds:\n",
    "    hard_sentence = train_set['sentences'][i]\n",
    "    if len(hard_sens) >= 200:\n",
    "        break\n",
    "    else:\n",
    "        hard_sens.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gzip.open(paths['dev'])\n",
    "new_data = []\n",
    "counter = 0\n",
    "for i in test:\n",
    "    bingus = json.loads(i)\n",
    "    if counter in hard_sens:\n",
    "        new_data.append(bingus)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hard_cases.json\", 'a') as f:\n",
    "    for i in new_data:\n",
    "        json.dump(i,f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checklist section:\n",
    "Gonna follow how they do in the official documentation.\n",
    "Pretty dumb donkey way of doing this. But hope it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the same stuff that they do in the doc. \n",
    "import checklist.editor\n",
    "import checklist.text_generation\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "import numpy as np\n",
    "import spacy\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.perturb import Perturb\n",
    "from spacy.lang.en.examples import sentences \n",
    "import random \n",
    "# Load editor. \n",
    "\n",
    "editor = checklist.editor.Editor()\n",
    "editor.tg\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sentences = dev_set['sentences'].values()\n",
    "parsed_data = list(nlp.pipe(sentences))\n",
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need at least 100 samples. What we can do is define some categories of difficult sentences for our logistic regression:\n",
    "\n",
    " - Negation: A negation such as \"I don't like the artist\" is difficult for our classifier to classify correctly, as it will see the work \"like\" which typically has positive connotations, but in this example the word \"don't\" infers that we means that like is used to infer negative sentiment of the artist, which our baseline logistic regression won't be able to detect.\n",
    "\n",
    " - Irony/Sarcasm. Since our baseline model basically just looks at individual words and learns if they are typically positive or negative, if a reviewer is being ironic/sarcastic and using words which indicate the opposite sentiment of what they truly mean, our logistic regression will fail. Fx with the sentence \"This album rocks, I love bleeding from my ears!\", it uses very positive words but since they are being ironic/sarcastic they use the positive words to convey a negative sentiment.\n",
    "\n",
    " - pos/neg. If a reviewer uses a mix of both positive and negative reviews, our logistic regression might become a bit confused and not know with any strong confidence which sentiment the review is. Fx \"I liked the old album but this new one sucks\" is hard because there is both the positive work \"liked\" and the negative word \"sucks\", and our logistic regression is too simple to understand that in this context it is the reviewed album that is bad.\n",
    "\n",
    "With these 3 categories, since we need at least 100 samples we can try to create some templates for them and generate say 40 samples each to get 120 total samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Creating lists of stuff for use in generating sentences #######\n",
    "\n",
    "# Constructing collection of music_nouns for use in all categories to reference whatever is being reviewed\n",
    "music_noun = ['project', 'artist', 'album', 'genre', 'compilation', 'ep',\n",
    "              'singer', 'band', 'guitar', 'drummer', 'guitarist', 'pianist',\n",
    "              'group']\n",
    "\n",
    "# Negations\n",
    "negations = ['don\\'t', 'can\\'t' , 'not', 'won\\'t', 'nothing']\n",
    "past_negations = ['didn\\'t', 'wouldn\\'t', 'couldn\\'t', 'shouldn\\'t']\n",
    "\n",
    "# Pos/Neg Adjectives\n",
    "pos_adj = ['adorable', 'amazing', 'awesome', 'beautiful', 'brilliant', 'captivating',\n",
    "           'creative', 'elegant', 'energetic' , 'excellent', 'exceptional', 'exciting',\n",
    "           'extraordinary', 'fabulous', 'fantastic', 'fun', 'good', 'great', 'happy',\n",
    "           'imaginative', 'incredible', 'nice', 'perfect', 'sweet', 'wonderful']\n",
    "neg_adj = ['abrasive', 'annoying', 'average', 'awful', 'bad', 'boring', 'careless',\n",
    "           'creepy', 'difficult', 'dreadful', 'frustrating', 'hard', 'horrible',\n",
    "           'lame', 'lousy', 'nasty', 'poor', 'ridiculous', 'rough', 'sad', 'terrible',\n",
    "           'ugly', 'unhappy', 'unpleasant', 'weird']\n",
    "\n",
    "# Positive Verbs in Present and Past Tenses\n",
    "pos_verb_present = ['admire', 'appreciate', 'enjoy', 'like', 'love', 'recommend', 'value', 'welcome']\n",
    "pos_verb_past = ['admired', 'appreciated', 'enjoyed', 'liked', 'loved', 'recommended', 'valued', 'welcomed']\n",
    "\n",
    "# Negative Verbs in Present and Past Tenses\n",
    "neg_verb_present = ['abhor', 'despise', 'dislike', 'dread', 'hate', 'loathe', 'regret', 'resent']\n",
    "neg_verb_past = ['abhorred', 'despised', 'disliked', 'dreaded', 'hated', 'loathed', 'regretted', 'resented']\n",
    "\n",
    "# Neutral Verbs in Present and Past Tenses\n",
    "neutral_verb_present = ['find', 'see']\n",
    "neutral_verb_past = ['found', 'saw']\n",
    "\n",
    "\n",
    "\n",
    "####### adding lexicons #######\n",
    "editor.add_lexicon('music_noun', music_noun, overwrite=True)\n",
    "\n",
    "editor.add_lexicon('negation', negations, overwrite=True)\n",
    "editor.add_lexicon('past_negation', past_negations, overwrite=True)\n",
    "\n",
    "editor.add_lexicon('pos_adj', pos_adj, overwrite=True)\n",
    "editor.add_lexicon('neg_adj', neg_adj, overwrite=True)\n",
    "\n",
    "editor.add_lexicon('pos_verb_present', pos_verb_present, overwrite=True)\n",
    "editor.add_lexicon('pos_verb_past', pos_verb_past, overwrite=True)\n",
    "\n",
    "editor.add_lexicon('neg_verb_present', neg_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_past', neg_verb_past, overwrite=True)\n",
    "\n",
    "editor.add_lexicon('neutral_verb_present', neutral_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_past', neutral_verb_past, overwrite=True)\n",
    "\n",
    "# mixed lexicons? not too sure how these work - Aidan\n",
    "editor.add_lexicon('pos_verb', pos_verb_present + pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb', neg_verb_present + neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb', neutral_verb_present + neutral_verb_past, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get 40 negations can create 2 templates for negations and randomly sample 20 sentences for each template\n",
    "template_negation_neg = list(editor.template('I {negation} {pos_verb_present} the {music_noun}')['data']) # template 1\n",
    "template_negation_pos = list(editor.template('I {negation} {neg_verb_present} the {music_noun}')['data']) # template 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_neg = random.sample(template_negation_neg, 20)\n",
    "negation_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_pos = random.sample(template_negation_pos, 20)\n",
    "negation_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irony/Sarcasm Templates\n",
    "template_ironsarc_pos = list(editor.template(\"Sooooo totally didn't {pos_verb_present} this {music_noun}...\")['data'])\n",
    "template_ironsarc_neg = list(editor.template(\"Sooooo totally didn't {neg_verb_present} this {music_noun}...\")['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative sentiment\n",
    "ironsarc_neg = random.sample(template_ironsarc_neg, 20)\n",
    "ironsarc_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive sentiment\n",
    "ironsarc_pos = random.sample(template_ironsarc_pos, 20)\n",
    "ironsarc_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos/neg templates\n",
    "template_posneg_pos = list(editor.template(\"I {neg_verb_past} the old {music_noun}, but this new one I {pos_verb_present}\")['data'])\n",
    "template_posneg_neg = list(editor.template(\"I {pos_verb_past} the old {music_noun}, but this new one I {neg_verb_present}\")['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posneg_pos = random.sample(template_posneg_pos, 20)\n",
    "posneg_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posneg_neg = random.sample(template_posneg_neg, 20)\n",
    "posneg_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving generated sentences to json file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting them all in a list for iteration:\n",
    "generated = [negation_neg, negation_pos, ironsarc_neg, ironsarc_pos, posneg_neg, posneg_pos]\n",
    "\n",
    "# creating json file so that if rerun this code always overwrites the existing file\n",
    "with open(\"hard_cases.json\", 'w') as f:\n",
    "    f.write('')\n",
    "\n",
    "# looping through and adding them all to json file\n",
    "for category in generated:\n",
    "    # getting to know categories and sentiments:\n",
    "    if category == negation_neg:\n",
    "        category_name = 'Negation'\n",
    "        sentiment = 'Negative'\n",
    "    elif category == negation_pos:\n",
    "        category_name = 'Negation'\n",
    "        sentiment = 'Positive'\n",
    "    elif category == ironsarc_neg:\n",
    "        category_name = 'Irony/Sarcasm'\n",
    "        sentiment = 'Negative'\n",
    "    elif category == ironsarc_pos:\n",
    "        category_name = 'Irony/Sarcasm'\n",
    "        sentiment = 'Positive'\n",
    "    elif category == posneg_neg:\n",
    "        category_name = 'Pos/Neg'\n",
    "        sentiment = 'Negative'\n",
    "    elif category == posneg_pos:\n",
    "        category_name = 'Pos/Neg'\n",
    "        sentiment = 'Positive'\n",
    "    \n",
    "    # adding to json file\n",
    "    with open(\"hard_cases.json\", 'a') as f:\n",
    "        for reviewText in category:\n",
    "            # writing all the stuff\n",
    "            json.dump({'reviewText': reviewText, 'sentiment': sentiment, 'category': category_name}, f)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_1 = list(editor.template('I {negation} {pos_verb_present} the {music_noun}')['data'])\n",
    "sen_2 = list(editor.template('I {past_negation} {neg_verb_present} the really {neg_adj} {music_noun}')['data'])\n",
    "irony_1 = list(editor.template('No the {neg_adj} {music_noun}, was totally {pos_adj} yeah...')['data'])\n",
    "negation_3 = list(editor.template('I actually {past_negation} {neg_verb_present} the {music_noun}')['data'])\n",
    "negation_4 = list(editor.template('Contrary to what i thought, the {music_noun}, wasn\\'t {neg_adj}')['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_1 = random.sample(sen_1, 15)\n",
    "samples_2 = random.sample(sen_2, 15)\n",
    "samples_3 = random.sample(irony_1, 15)\n",
    "samples_4 = random.sample(negation_3, 15)\n",
    "samples_5 = random.sample(negation_4, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
