{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project phase 1: Baseline\n",
    "\n",
    "The goal of this phase is to create a baseline model. Note that the word baseline can mean different things. In the course we distinguished three different types of baselines:\n",
    "* 1. The simplest possible approach (majority baseline, i.e. everything is positive or noun)\n",
    "* 2. A simple machine learning classifier (logistic regression with words as features)\n",
    "* 3. The ``state-of-the-art'' approach on which you want to improve (your starting point)\n",
    "\n",
    "For this phase you need to make a number 2 or 3 baseline. \n",
    "\n",
    "If you plan to have a research question like: can we improve sentiment detection systems by doing X, the answer to the question is the most relevant if you have a competetive baseline (3). In this case we would suggest to use a BiLSTM or even a transformer based model, so that you can re-use the baseline for the final research question (phase 3).\n",
    "\n",
    "You should pick one of the following tasks to create your baseline for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Sentiment classification\n",
    "* The data can be found in the `classification` folder.\n",
    "* The goal is to predict the label in the `sentiment` field.\n",
    "* **You have to upload the predictions of `music_reviews_test_masked.json.gz` to CodaLab. (The link will be posted here on monday). Note that the format should match the json files in the repository.**\n",
    "* **Also upload a .txt file on LearnIt (one per group) with a short description of your baseline.**\n",
    "\n",
    "The data can be read like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "for line in gzip.open('classification/music_reviews_dev.json.gz'):\n",
    "    review_data = json.loads(line)\n",
    "    for key in review_data:\n",
    "        print('\"' + key +'\": ' + str(review_data[key]))\n",
    "    break\n",
    "paths = {'train':'classification/music_reviews_train.json.gz',\n",
    "        'test':'classification/music_reviews_test_masked.json.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = {}\n",
    "train = gzip.open(paths['train'])\n",
    "counter1 = 0\n",
    "counter2 = 0\n",
    "counter3 = 0\n",
    "train_no_reviewText = []\n",
    "labels = {}\n",
    "train_sentences = {}\n",
    "for line in train:\n",
    "    counter1 +=1\n",
    "    #print(line)\n",
    "    if 'reviewText' in json.loads(line).keys():\n",
    "        train_sentences[counter3] = json.loads(line)['reviewText']\n",
    "        counter3 += 1\n",
    "        for word in json.loads(line)['reviewText'].split():\n",
    "            if word not in train_vocab.keys():\n",
    "                train_vocab[word] = counter2\n",
    "                counter2 += 1\n",
    "    else:\n",
    "        train_no_reviewText.append(counter1)\n",
    "print(counter3,counter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gram matrix \n",
    "m1 = torch.zeros(counter3, counter2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need idx2word\n",
    "idx2word = dict([(value, key) for key, value in train_vocab.items()])\n",
    "\n",
    "# Begin correcting gram matrix\n",
    "\n",
    "for sen in train_sentences: \n",
    "    for word in train_sentences[sen].split(): \n",
    "        m1[sen, train_vocab[word]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = {}\n",
    "train = gzip.open(paths['train'])\n",
    "train_labels = {}\n",
    "counter = 0\n",
    "for line in train:\n",
    "    a = json.loads(line)\n",
    "    if 'reviewText' in a.keys():\n",
    "        if a['sentiment'] == 'positive':\n",
    "            train_labels[counter] = 1\n",
    "        elif a['sentiment'] == 'negative': \n",
    "            train_labels[counter] = 0\n",
    "        counter +=1\n",
    "\n",
    "        \n",
    "#len(labels)\n",
    "#print(type(labels))\n",
    "\n",
    "\n",
    "\n",
    "counter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "num_batches = int(len(m1)/batch_size)\n",
    "train_feats_batches = m1[:batch_size*num_batches].view(num_batches,batch_size, counter2)\n",
    "for feats_batch in train_feats_batches:\n",
    "    print(feats_batch.shape)\n",
    "\n",
    "bingus = list(train_labels.values())\n",
    "bingus = torch.FloatTensor(bingus)\n",
    "\n",
    "num_batches = int(len(bingus)/batch_size)\n",
    "train_label_batches = bingus[:batch_size*num_batches].view(num_batches,batch_size,1)\n",
    "counter = 1\n",
    "for feats_batch in train_label_batches:\n",
    "    counter+=1\n",
    "    print(feats_batch.shape)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode test labels\n",
    "test_vocab = {}\n",
    "test = gzip.open(paths['test'])\n",
    "counter1 = 0\n",
    "counter2 = 0\n",
    "counter3 = 0\n",
    "test_no_reviewText = []\n",
    "test_labels = {}\n",
    "test_sentences = {}\n",
    "for line in test:\n",
    "    counter1 +=1\n",
    "    #print(line)\n",
    "    if 'reviewText' in json.loads(line).keys():\n",
    "        test_sentences[counter3] = json.loads(line)['reviewText']\n",
    "        counter3 += 1\n",
    "        for word in json.loads(line)['reviewText'].split():\n",
    "            if word not in train_vocab.keys():\n",
    "                test_vocab[word] = counter2\n",
    "                counter2 += 1\n",
    "    else:\n",
    "        test_no_reviewText.append(counter1)\n",
    "print('Vocab size: ', counter2)\n",
    "        \n",
    "# Construct gram matrix\n",
    "m2 = torch.zeros(counter3, 226347)\n",
    "print('m2 constructed!')\n",
    "\n",
    "\n",
    "# Need idx2word\n",
    "idx2word = dict([(value, key) for key, value in train_vocab.items()])\n",
    "print('idx2word done!')\n",
    "\n",
    "\n",
    "# Begin correcting gram matrix\n",
    "for sen in test_sentences: \n",
    "    for word in test_sentences[sen].split(): \n",
    "        if word in train_vocab.keys():\n",
    "            m2[sen, train_vocab[word]] = 1\n",
    "print('Gram matrix done')\n",
    "\n",
    "#Note labels\n",
    "test = gzip.open(paths['test'])\n",
    "test_labels = {}\n",
    "counter = 0\n",
    "for line in test:\n",
    "    a = json.loads(line)\n",
    "    if 'reviewText' in a.keys():\n",
    "        if a['sentiment'] == 'positive':\n",
    "            test_labels[counter] = 1\n",
    "        elif a['sentiment'] == 'negative': \n",
    "            test_labels[counter] = 0\n",
    "        counter +=1\n",
    "print('Labels noted!')\n",
    "        \n",
    "#Divide into batches\n",
    "\n",
    "batch_size = 2499\n",
    "num_batches = int(len(m2)/batch_size)\n",
    "test_feats_batches = m2[:batch_size*num_batches].view(num_batches,batch_size, 226347)\n",
    "print('Feature Matrix shapes: ')\n",
    "for feats_batch in test_feats_batches:\n",
    "    print(feats_batch.shape)\n",
    "bingus = list(test_labels.values())\n",
    "bingus = torch.FloatTensor(bingus)\n",
    "num_batches = int(len(bingus)/batch_size)\n",
    "test_label_batches = bingus[:batch_size*num_batches].view(num_batches,batch_size,1)\n",
    "print('label matrix shapes: ')\n",
    "for feats_batch in test_label_batches:\n",
    "    print(feats_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(filepath):\n",
    "    test_vocab = {}\n",
    "    test = gzip.open(filepath)\n",
    "    counter1 = 0\n",
    "    counter2 = 0\n",
    "    counter3 = 0\n",
    "    test_no_reviewText = []\n",
    "    test_labels = {}\n",
    "    test_sentences = {}\n",
    "    for line in test:\n",
    "        counter1 +=1\n",
    "        #print(line)\n",
    "        if 'reviewText' in json.loads(line).keys():\n",
    "            test_sentences[counter3] = json.loads(line)['reviewText']\n",
    "            counter3 += 1\n",
    "            for word in json.loads(line)['reviewText'].split():\n",
    "                if word not in train_vocab.keys():\n",
    "                    test_vocab[word] = counter2\n",
    "                    counter2 += 1\n",
    "        else:\n",
    "            test_no_reviewText.append(counter1)\n",
    "    final_dict = {'line_count' : counter1,\n",
    "                 'review_count' : counter3,\n",
    "                 'vocab_size' : counter2,\n",
    "                 'no_text_reviews' : test_no_reviewText,\n",
    "                 'labels' : test_labels,\n",
    "                 'vocabulary' : test_vocab,\n",
    "                 'sentences' : test_sentences}\n",
    "    return final_dict\n",
    "\n",
    "def construct_gram(vocab, num_sen, vocab_len, sentences): \n",
    "    # Construct gram matrix\n",
    "    m2 = torch.zeros(num_sen, vocab_len)\n",
    "    print('m2 constructed!')\n",
    "    for sen in sentences: \n",
    "        for word in sentences[sen].split(): \n",
    "            m2[sen, vocab[word]] = 1\n",
    "    print('Gram matrix done')\n",
    "    return m2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = LogisticRegression()\n",
    "#for feat, label in zip(train_feats_batches,train_label_batches):\n",
    "#    model.fit(feat,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {}\n",
    "counter = 0\n",
    "for batch in test_feats_batches:\n",
    "    preds[counter] = model.predict(batch)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr = []\n",
    "for i in preds:\n",
    "    for j in preds[i]:\n",
    "        new_arr.append(j)\n",
    "len(new_arr)\n",
    "new_arr = np.array(new_arr)\n",
    "new_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred, true in zip(preds, test_label_batches):\n",
    "    print(classification_report(preds[pred], true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gzip.open(paths['test'])\n",
    "counter = 0\n",
    "new_data = []\n",
    "for i in test:\n",
    "    bingus = json.loads(i)\n",
    "    if new_arr[counter] == 0:\n",
    "        bingus['sentiment'] = 'negative'\n",
    "    elif new_arr[counter] == 1:\n",
    "        bingus['sentiment'] = 'positive'\n",
    "    new_data.append(bingus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new_data:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"final.json\", 'a') as f:\n",
    "#    for i in new_data:\n",
    "#        json.dump(i,f)\n",
    "#        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Break it down\n",
    "\n",
    "In this part of the project, we are tasked with breaking our own model down, to try and improve it. <br> \n",
    "\n",
    "### Suggested methods: \n",
    "- Change language\n",
    "- More negation\n",
    "- Reviews of other products\n",
    "\n",
    "### Things we should also consider: \n",
    "- Better tokenization\n",
    "- Model tuning\n",
    "- Acutually using development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better tokenization: \n",
    "'''\n",
    "1. Look up better regex expression\n",
    "2. Remove stopwords\n",
    "3. implement padding(might have to wait on that one lmao)\n",
    "4. Use a way more sophisticated model. (might wanna wait on that one too)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reopen file + imports: \n",
    "import gzip\n",
    "import json\n",
    "import torch \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# This is how they load the data ------------------------------------------\n",
    "#for line in gzip.open('../classification/music_reviews_dev.json.gz'):\n",
    "#    review_data = json.loads(line)\n",
    "#    for key in review_data:\n",
    "#        print('\"' + key +'\": ' + str(review_data[key]))\n",
    "#    break\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "paths = {'train':'../classification/music_reviews_train.json.gz',\n",
    "        'test':'../classification/music_reviews_test_masked.json.gz',\n",
    "        'dev' : '../classification/music_reviews_dev.json.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabs built using TweetTokenizer\n",
    "# \n",
    "\n",
    "\n",
    "def build_vocab(filepath):\n",
    "    train_vocab = {}\n",
    "    train = gzip.open(filepath)\n",
    "    counter1 = 0\n",
    "    counter2 = 0\n",
    "    counter3 = 0\n",
    "    counter = 0\n",
    "    no_reviewText = []\n",
    "    labels = {}\n",
    "    sentences = {}\n",
    "    tokenizer = TweetTokenizer()\n",
    "    for line in train:\n",
    "        counter1 +=1\n",
    "        #print(line)\n",
    "        if 'reviewText' in json.loads(line).keys():\n",
    "            a = json.loads(line)\n",
    "            sentences[counter3] = a['reviewText']\n",
    "            counter3 += 1\n",
    "            if a['sentiment'] == 'positive':\n",
    "                labels[counter] = 1\n",
    "            elif a['sentiment'] == 'negative': \n",
    "                labels[counter] = 0\n",
    "            counter +=1\n",
    "            for word in tokenizer.tokenize(json.loads(line)['reviewText']):\n",
    "                if word not in train_vocab.keys():\n",
    "                    train_vocab[word] = counter2\n",
    "                    counter2 += 1\n",
    "        else:\n",
    "            no_reviewText.append(counter1)\n",
    "    final_dict = {'line_count' : counter1,\n",
    "                 'review_count' : counter3,\n",
    "                 'vocab_size' : counter2,\n",
    "                 'no_text_reviews' : no_reviewText,\n",
    "                 'labels' : labels,\n",
    "                 'vocabulary' : train_vocab,\n",
    "                 'sentences' : sentences}\n",
    "    return final_dict\n",
    "\n",
    "train_set =  build_vocab(paths['train'])\n",
    "dev_set = build_vocab(paths['dev'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\Users\\builder\\tkoch\\workspace\\pytorch\\pytorch_1647970138273\\work\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 44822182944 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m                 m1[sen, vocab[word]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m m1\n\u001b[1;32m---> 14\u001b[0m train_unigram \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_unigram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvocabulary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentences\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_batches\u001b[39m(matrix, batch_size,labels): \n\u001b[0;32m     17\u001b[0m     num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(matrix)\u001b[38;5;241m/\u001b[39mbatch_size)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mcreate_unigram\u001b[1;34m(vocab, sentences, tokenzier)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_unigram\u001b[39m(vocab, sentences, tokenzier):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Create matrix\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     m1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Correct indices\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sentences)): \n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\Users\\builder\\tkoch\\workspace\\pytorch\\pytorch_1647970138273\\work\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 44822182944 bytes."
     ]
    }
   ],
   "source": [
    "# Might wanna run tests again just to see if the new tokenization improved performance in any way. \n",
    "tokenizer = TweetTokenizer()\n",
    "# unigrams : \n",
    "def create_unigram(vocab, sentences, tokenzier):\n",
    "    # Create matrix\n",
    "    m1 = torch.zeros(len(sentences), len(vocab))\n",
    "    # Correct indices\n",
    "    for sen in range(len(sentences)): \n",
    "        for word in tokenizer.tokenize(sentences[sen]): \n",
    "            if word in vocab.keys():\n",
    "                m1[sen, vocab[word]] = 1\n",
    "    return m1\n",
    "\n",
    "train_unigram = create_unigram(train_set['vocabulary'], train_set['sentences'], tokenizer)\n",
    "\n",
    "def create_batches(matrix, batch_size,labels): \n",
    "    num_batches = int(len(matrix)/batch_size)\n",
    "    feats_batches = matrix[:batch_size*num_batches].view(num_batches,batch_size, matrix.shape[1])\n",
    "    bingus = torch.FloatTensor(list(labels.values()))\n",
    "    num_batches = int(len(bingus)/batch_size)\n",
    "    label_batches = bingus[:batch_size*num_batches].view(num_batches,batch_size,1)\n",
    "    return feats_batches, label_batches\n",
    "train_feat_batches = create_batches(train_unigram, 2499, train_set['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_feat_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m labels_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mtrain_feat_batches\u001b[49m[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      2\u001b[0m feat_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(train_feat_batches[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_feat_batches' is not defined"
     ]
    }
   ],
   "source": [
    "labels_batches = list(train_feat_batches[1])\n",
    "feat_batches = list(train_feat_batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feat, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mfeat_batches\u001b[49m, labels_batches):\n\u001b[0;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(feat,label)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_batches' is not defined"
     ]
    }
   ],
   "source": [
    "# Make model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train model\n",
    "\n",
    "for feat, label in zip(feat_batches, labels_batches):\n",
    "    model.fit(feat,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_unigram = create_unigram(train_set['vocabulary'], dev_set['sentences'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dev_batches \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_batches\u001b[49m(dev_unigram,\u001b[38;5;241m2499\u001b[39m,dev_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m preds \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      3\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_batches' is not defined"
     ]
    }
   ],
   "source": [
    "dev_batches = create_batches(dev_unigram,2499,dev_set['labels'])\n",
    "preds = {}\n",
    "counter = 0\n",
    "for batch in dev_batches[0]:\n",
    "    preds[counter] = model.predict(batch)\n",
    "    counter+=1\n",
    "new_arr = []\n",
    "for i in preds:\n",
    "    for j in preds[i]:\n",
    "        new_arr.append(j)\n",
    "len(new_arr)\n",
    "new_arr = np.array(new_arr)\n",
    "for pred, true in zip(preds, dev_batches[1]):\n",
    "    print(classification_report(preds[pred], true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_preds = {}\n",
    "counter = 0\n",
    "for batch, pred_dict, true_dict in zip(dev_batches[0], preds.values(), dev_batches[1]):\n",
    "    for sentence, pred, true in zip(batch, pred_dict, true_dict):\n",
    "        if pred != true:\n",
    "            hard_preds[counter] = int(pred)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing the first 200 misclassification sentences\n",
    "hard_sens = []\n",
    "for i in hard_preds:\n",
    "    hard_sentence = train_set['sentences'][i]\n",
    "    if len(hard_sens) >= 200:\n",
    "        break\n",
    "    else:\n",
    "        hard_sens.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gzip.open(paths['dev'])\n",
    "new_data = []\n",
    "counter = 0\n",
    "for i in test:\n",
    "    bingus = json.loads(i)\n",
    "    if counter in hard_sens:\n",
    "        new_data.append(bingus)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hard_cases.json\", 'a') as f:\n",
    "    for i in new_data:\n",
    "        json.dump(i,f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checklist section:\n",
    "Gonna follow how they do in the official documentation.\n",
    "Pretty dumb donkey way of doing this. But hope it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the same stuff that they do in the doc. \n",
    "import checklist.editor\n",
    "import checklist.text_generation\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "import numpy as np\n",
    "import spacy\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.perturb import Perturb\n",
    "from spacy.lang.en.examples import sentences \n",
    "import random \n",
    "# Load editor. \n",
    "\n",
    "editor = checklist.editor.Editor()\n",
    "editor.tg\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sentences = dev_set['sentences'].values()\n",
    "parsed_data = list(nlp.pipe(sentences))\n",
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My dentist recommended this as a relaxation technique for dental visits. They give me an ipod with headphones, play this on it and it relieves some of the stress of dental treatment, which I dislike intensely.\n",
       "It worked so well that I bought my own copy to try at home. I fall asleep after a couple of minutes and stay asleep. Instead of tossing and turning, I hardly move at all. Highly recommend."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need at least 100 samples. What we can do is define some categories of difficult sentences for our logistic regression:\n",
    "\n",
    " - Negation: A negation such as \"I don't like the artist\" is difficult for our classifier to classify correctly, as it will see the work \"like\" which typically has positive connotations, but in this example the word \"don't\" infers that we means that like is used to infer negative sentiment of the artist, which our baseline logistic regression won't be able to detect.\n",
    "\n",
    " - Irony/Sarcasm. Since our baseline model basically just looks at individual words and learns if they are typically positive or negative, if a reviewer is being ironic/sarcastic and using words which indicate the opposite sentiment of what they truly mean, our logistic regression will fail. Fx with the sentence \"This album rocks, I love bleeding from my ears!\", it uses very positive words but since they are being ironic/sarcastic they use the positive words to convey a negative sentiment.\n",
    "\n",
    " - pos/neg. If a reviewer uses a mix of both positive and negative reviews, our logistic regression might become a bit confused and not know with any strong confidence which sentiment the review is. Fx \"I liked the old album but this new one sucks\" is hard because there is both the positive work \"liked\" and the negative word \"sucks\", and our logistic regression is too simple to understand that in this context it is the reviewed album that is bad.\n",
    "\n",
    "With these 3 categories, since we need at least 100 samples we can try to create some templates for them and generate say 40 samples each to get 120 total samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Creating lists of stuff for use in generating sentences #######\n",
    "\n",
    "# Constructing collection of music_nouns for use in all categories to reference whatever is being reviewed\n",
    "music_noun = ['project', 'artist', 'album', 'genre', 'compilation', 'ep',\n",
    "              'singer', 'band', 'guitar', 'drummer', 'guitarist', 'pianist',\n",
    "              'group']\n",
    "\n",
    "# Negations\n",
    "negations = ['don\\'t', 'can\\'t' , 'not', 'won\\'t', 'nothing']\n",
    "past_negations = ['didn\\'t', 'wouldn\\'t', 'couldn\\'t', 'shouldn\\'t']\n",
    "\n",
    "# Pos/Neg Adjectives\n",
    "pos_adj = ['adorable', 'amazing', 'awesome', 'beautiful', 'brilliant', 'captivating',\n",
    "           'creative', 'elegant', 'energetic' , 'excellent', 'exceptional', 'exciting',\n",
    "           'extraordinary', 'fabulous', 'fantastic', 'fun', 'good', 'great', 'happy',\n",
    "           'imaginative', 'incredible', 'nice', 'perfect', 'sweet', 'wonderful']\n",
    "neg_adj = ['abrasive', 'annoying', 'average', 'awful', 'bad', 'boring', 'careless',\n",
    "           'creepy', 'difficult', 'dreadful', 'frustrating', 'hard', 'horrible',\n",
    "           'lame', 'lousy', 'nasty', 'poor', 'ridiculous', 'rough', 'sad', 'terrible',\n",
    "           'ugly', 'unhappy', 'unpleasant', 'weird']\n",
    "\n",
    "# Positive Verbs in Present and Past Tenses\n",
    "pos_verb_present = ['admire', 'appreciate', 'enjoy', 'like', 'love', 'recommend', 'value', 'welcome']\n",
    "pos_verb_past = ['admired', 'appreciated', 'enjoyed', 'liked', 'loved', 'recommended', 'valued', 'welcomed']\n",
    "\n",
    "# Negative Verbs in Present and Past Tenses\n",
    "neg_verb_present = ['abhor', 'despise', 'dislike', 'dread', 'hate', 'loathe', 'regret', 'resent']\n",
    "neg_verb_past = ['abhorred', 'despised', 'disliked', 'dreaded', 'hated', 'loathed', 'regretted', 'resented']\n",
    "\n",
    "# Neutral Verbs in Present and Past Tenses\n",
    "neutral_verb_present = ['find', 'see']\n",
    "neutral_verb_past = ['found', 'saw']\n",
    "\n",
    "\n",
    "\n",
    "####### adding lexicons #######\n",
    "editor.add_lexicon('music_noun', music_noun, overwrite=True)\n",
    "\n",
    "editor.add_lexicon('negation', negations, overwrite=True)\n",
    "editor.add_lexicon('past_negation', past_negations, overwrite=True)\n",
    "\n",
    "editor.add_lexicon('pos_adj', pos_adj, overwrite=True)\n",
    "editor.add_lexicon('neg_adj', neg_adj, overwrite=True)\n",
    "\n",
    "editor.add_lexicon('pos_verb_present', pos_verb_present, overwrite=True)\n",
    "editor.add_lexicon('pos_verb_past', pos_verb_past, overwrite=True)\n",
    "\n",
    "editor.add_lexicon('neg_verb_present', neg_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_past', neg_verb_past, overwrite=True)\n",
    "\n",
    "editor.add_lexicon('neutral_verb_present', neutral_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_past', neutral_verb_past, overwrite=True)\n",
    "\n",
    "# mixed lexicons? not too sure how these work - Aidan\n",
    "editor.add_lexicon('pos_verb', pos_verb_present + pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb', neg_verb_present + neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb', neutral_verb_present + neutral_verb_past, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get 40 negations can create 2 templates for negations and randomly sample 20 sentences for each template\n",
    "template_negation_neg = list(editor.template('I {negation} {pos_verb_present} the {music_noun}')['data']) # template 1\n",
    "template_negation_pos = list(editor.template('I {negation} {neg_verb_present} the {music_noun}')['data']) # template 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I don't value the compilation\",\n",
       " \"I don't enjoy the album\",\n",
       " 'I nothing admire the guitar',\n",
       " 'I nothing admire the singer',\n",
       " 'I not like the genre',\n",
       " \"I can't enjoy the guitar\",\n",
       " 'I nothing welcome the band',\n",
       " \"I can't admire the guitar\",\n",
       " 'I not value the group',\n",
       " 'I nothing love the pianist',\n",
       " \"I don't admire the pianist\",\n",
       " \"I won't value the genre\",\n",
       " \"I don't love the group\",\n",
       " \"I don't recommend the project\",\n",
       " 'I not welcome the group',\n",
       " \"I don't welcome the pianist\",\n",
       " \"I don't enjoy the drummer\",\n",
       " 'I nothing recommend the album',\n",
       " 'I not welcome the pianist',\n",
       " \"I won't appreciate the singer\"]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negation_neg = random.sample(template_negation_neg, 20)\n",
    "negation_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I don't dislike the guitarist\",\n",
       " 'I nothing abhor the drummer',\n",
       " \"I don't despise the guitar\",\n",
       " \"I can't dislike the ep\",\n",
       " 'I not dread the guitar',\n",
       " 'I not dislike the drummer',\n",
       " 'I nothing dread the ep',\n",
       " 'I nothing regret the group',\n",
       " \"I won't dread the drummer\",\n",
       " 'I not resent the album',\n",
       " \"I don't dislike the album\",\n",
       " \"I won't resent the guitarist\",\n",
       " \"I can't regret the ep\",\n",
       " \"I don't dislike the pianist\",\n",
       " 'I nothing loathe the guitar',\n",
       " \"I won't dislike the project\",\n",
       " 'I not hate the project',\n",
       " 'I nothing dislike the singer',\n",
       " \"I can't abhor the singer\",\n",
       " 'I nothing abhor the artist']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negation_pos = random.sample(template_negation_pos, 20)\n",
    "negation_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irony/Sarcasm Templates\n",
    "template_ironsarc_pos = list(editor.template(\"Sooooo totally didn't {pos_verb_present} this {music_noun}...\")['data'])\n",
    "template_ironsarc_neg = list(editor.template(\"Sooooo totally didn't {neg_verb_present} this {music_noun}...\")['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Sooooo totally didn't regret this drummer...\",\n",
       " \"Sooooo totally didn't despise this ep...\",\n",
       " \"Sooooo totally didn't resent this genre...\",\n",
       " \"Sooooo totally didn't dread this album...\",\n",
       " \"Sooooo totally didn't dread this singer...\",\n",
       " \"Sooooo totally didn't resent this band...\",\n",
       " \"Sooooo totally didn't resent this pianist...\",\n",
       " \"Sooooo totally didn't abhor this genre...\",\n",
       " \"Sooooo totally didn't hate this drummer...\",\n",
       " \"Sooooo totally didn't loathe this guitarist...\",\n",
       " \"Sooooo totally didn't dread this artist...\",\n",
       " \"Sooooo totally didn't loathe this ep...\",\n",
       " \"Sooooo totally didn't resent this artist...\",\n",
       " \"Sooooo totally didn't regret this pianist...\",\n",
       " \"Sooooo totally didn't resent this singer...\",\n",
       " \"Sooooo totally didn't loathe this singer...\",\n",
       " \"Sooooo totally didn't dislike this pianist...\",\n",
       " \"Sooooo totally didn't loathe this pianist...\",\n",
       " \"Sooooo totally didn't hate this guitarist...\",\n",
       " \"Sooooo totally didn't loathe this band...\"]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative sentiment\n",
    "ironsarc_neg = random.sample(template_ironsarc_neg, 20)\n",
    "ironsarc_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Sooooo totally didn't like this genre...\",\n",
       " \"Sooooo totally didn't enjoy this guitarist...\",\n",
       " \"Sooooo totally didn't value this artist...\",\n",
       " \"Sooooo totally didn't like this guitarist...\",\n",
       " \"Sooooo totally didn't enjoy this project...\",\n",
       " \"Sooooo totally didn't like this compilation...\",\n",
       " \"Sooooo totally didn't welcome this drummer...\",\n",
       " \"Sooooo totally didn't appreciate this singer...\",\n",
       " \"Sooooo totally didn't love this group...\",\n",
       " \"Sooooo totally didn't appreciate this artist...\",\n",
       " \"Sooooo totally didn't recommend this band...\",\n",
       " \"Sooooo totally didn't like this album...\",\n",
       " \"Sooooo totally didn't appreciate this guitarist...\",\n",
       " \"Sooooo totally didn't value this project...\",\n",
       " \"Sooooo totally didn't appreciate this drummer...\",\n",
       " \"Sooooo totally didn't value this band...\",\n",
       " \"Sooooo totally didn't appreciate this guitar...\",\n",
       " \"Sooooo totally didn't value this singer...\",\n",
       " \"Sooooo totally didn't recommend this guitar...\",\n",
       " \"Sooooo totally didn't recommend this artist...\"]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive sentiment\n",
    "ironsarc_pos = random.sample(template_ironsarc_pos, 20)\n",
    "ironsarc_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos/neg templates\n",
    "template_posneg_pos = list(editor.template(\"I {neg_verb_past} the old {music_noun}, but this new one I {pos_verb_present}\")['data'])\n",
    "template_posneg_neg = list(editor.template(\"I {pos_verb_past} the old {music_noun}, but this new one I {neg_verb_present}\")['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I abhorred the old band, but this new one I recommend',\n",
       " 'I dreaded the old ep, but this new one I love',\n",
       " 'I dreaded the old genre, but this new one I value',\n",
       " 'I loathed the old drummer, but this new one I enjoy',\n",
       " 'I hated the old guitarist, but this new one I recommend',\n",
       " 'I abhorred the old group, but this new one I value',\n",
       " 'I loathed the old singer, but this new one I enjoy',\n",
       " 'I abhorred the old ep, but this new one I welcome',\n",
       " 'I hated the old project, but this new one I welcome',\n",
       " 'I despised the old guitar, but this new one I enjoy',\n",
       " 'I loathed the old project, but this new one I admire',\n",
       " 'I dreaded the old guitar, but this new one I enjoy',\n",
       " 'I hated the old album, but this new one I recommend',\n",
       " 'I despised the old artist, but this new one I enjoy',\n",
       " 'I hated the old drummer, but this new one I admire',\n",
       " 'I dreaded the old group, but this new one I appreciate',\n",
       " 'I loathed the old artist, but this new one I admire',\n",
       " 'I disliked the old drummer, but this new one I admire',\n",
       " 'I regretted the old pianist, but this new one I like',\n",
       " 'I dreaded the old guitarist, but this new one I admire']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posneg_pos = random.sample(template_posneg_pos, 20)\n",
    "posneg_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I loved the old project, but this new one I resent',\n",
       " 'I recommended the old drummer, but this new one I despise',\n",
       " 'I appreciated the old album, but this new one I loathe',\n",
       " 'I recommended the old project, but this new one I resent',\n",
       " 'I enjoyed the old singer, but this new one I despise',\n",
       " 'I liked the old singer, but this new one I despise',\n",
       " 'I enjoyed the old pianist, but this new one I hate',\n",
       " 'I valued the old guitar, but this new one I loathe',\n",
       " 'I admired the old guitarist, but this new one I hate',\n",
       " 'I liked the old genre, but this new one I dislike',\n",
       " 'I recommended the old album, but this new one I regret',\n",
       " 'I loved the old artist, but this new one I hate',\n",
       " 'I liked the old ep, but this new one I hate',\n",
       " 'I admired the old genre, but this new one I regret',\n",
       " 'I admired the old album, but this new one I despise',\n",
       " 'I admired the old drummer, but this new one I loathe',\n",
       " 'I welcomed the old compilation, but this new one I despise',\n",
       " 'I enjoyed the old band, but this new one I despise',\n",
       " 'I valued the old genre, but this new one I abhor',\n",
       " 'I welcomed the old genre, but this new one I resent']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posneg_neg = random.sample(template_posneg_neg, 20)\n",
    "posneg_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving generated sentences to json file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting them all in a list for iteration:\n",
    "generated = [negation_neg, negation_pos, ironsarc_neg, ironsarc_pos, posneg_neg, posneg_pos]\n",
    "\n",
    "# creating json file so that if rerun this code always overwrites the existing file\n",
    "with open(\"hard_cases.json\", 'w') as f:\n",
    "    f.write('')\n",
    "\n",
    "# looping through and adding them all to json file\n",
    "for category in generated:\n",
    "    # getting to know categories and sentiments:\n",
    "    if category == negation_neg:\n",
    "        category_name = 'Negation'\n",
    "        sentiment = 'Negative'\n",
    "    elif category == negation_pos:\n",
    "        category_name = 'Negation'\n",
    "        sentiment = 'Positive'\n",
    "    elif category == ironsarc_neg:\n",
    "        category_name = 'Irony/Sarcasm'\n",
    "        sentiment = 'Negative'\n",
    "    elif category == ironsarc_pos:\n",
    "        category_name = 'Irony/Sarcasm'\n",
    "        sentiment = 'Positive'\n",
    "    elif category == posneg_neg:\n",
    "        category_name = 'Pos/Neg'\n",
    "        sentiment = 'Negative'\n",
    "    elif category == posneg_pos:\n",
    "        category_name = 'Pos/Neg'\n",
    "        sentiment = 'Positive'\n",
    "    \n",
    "    # adding to json file\n",
    "    with open(\"hard_cases.json\", 'a') as f:\n",
    "        for reviewText in category:\n",
    "            # writing all the stuff\n",
    "            json.dump({'reviewText': reviewText, 'sentiment': sentiment, 'category': category_name}, f)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_1 = list(editor.template('I {negation} {pos_verb_present} the {music_noun}')['data'])\n",
    "sen_2 = list(editor.template('I {past_negation} {neg_verb_present} the really {neg_adj} {music_noun}')['data'])\n",
    "irony_1 = list(editor.template('No the {neg_adj} {music_noun}, was totally {pos_adj} yeah...')['data'])\n",
    "negation_3 = list(editor.template('I actually {past_negation} {neg_verb_present} the {music_noun}')['data'])\n",
    "negation_4 = list(editor.template('Contrary to what i thought, the {music_noun}, wasn\\'t {neg_adj}')['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_1 = random.sample(sen_1, 15)\n",
    "samples_2 = random.sample(sen_2, 15)\n",
    "samples_3 = random.sample(irony_1, 15)\n",
    "samples_4 = random.sample(negation_3, 15)\n",
    "samples_5 = random.sample(negation_4, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I don't appreciate the ep\",\n",
       " 'I not welcome the drummer',\n",
       " \"I don't like the genre\",\n",
       " \"I can't appreciate the artist\",\n",
       " 'I not recommend the drummer',\n",
       " \"I can't welcome the artist\",\n",
       " \"I don't enjoy the singer\",\n",
       " \"I won't love the artist\",\n",
       " \"I don't welcome the ep\",\n",
       " 'I nothing like the guitarist',\n",
       " 'I nothing appreciate the band',\n",
       " \"I don't recommend the genre\",\n",
       " \"I can't value the genre\",\n",
       " \"I won't appreciate the project\",\n",
       " 'I not enjoy the album']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I shouldn't regret the really boring genre\",\n",
       " \"I couldn't abhor the really rough album\",\n",
       " \"I shouldn't regret the really boring album\",\n",
       " \"I didn't abhor the really poor guitar\",\n",
       " \"I shouldn't hate the really sad guitarist\",\n",
       " \"I couldn't regret the really hard ep\",\n",
       " \"I didn't abhor the really nasty singer\",\n",
       " \"I couldn't regret the really bad singer\",\n",
       " \"I wouldn't abhor the really terrible drummer\",\n",
       " \"I didn't regret the really terrible album\",\n",
       " \"I couldn't dislike the really rough singer\",\n",
       " \"I wouldn't dread the really nasty singer\",\n",
       " \"I shouldn't regret the really hard ep\",\n",
       " \"I wouldn't abhor the really sad ep\",\n",
       " \"I didn't hate the really sad ep\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No the sad album, was totally brilliant yeah...',\n",
       " 'No the ugly drummer, was totally wonderful yeah...',\n",
       " 'No the ugly compilation, was totally extraordinary yeah...',\n",
       " 'No the terrible drummer, was totally happy yeah...',\n",
       " 'No the average album, was totally awesome yeah...',\n",
       " 'No the nasty singer, was totally wonderful yeah...',\n",
       " 'No the lame artist, was totally good yeah...',\n",
       " 'No the bad ep, was totally fantastic yeah...',\n",
       " 'No the unhappy project, was totally extraordinary yeah...',\n",
       " 'No the unpleasant ep, was totally incredible yeah...',\n",
       " 'No the weird project, was totally extraordinary yeah...',\n",
       " 'No the difficult ep, was totally good yeah...',\n",
       " 'No the rough ep, was totally exciting yeah...',\n",
       " 'No the hard artist, was totally great yeah...',\n",
       " 'No the awful artist, was totally adorable yeah...']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I actually didn't abhor the compilation\",\n",
       " \"I actually couldn't hate the guitar\",\n",
       " \"I actually didn't hate the singer\",\n",
       " \"I actually didn't hate the project\",\n",
       " \"I actually wouldn't hate the album\",\n",
       " \"I actually couldn't hate the project\",\n",
       " \"I actually couldn't despise the guitarist\",\n",
       " \"I actually shouldn't abhor the album\",\n",
       " \"I actually couldn't abhor the genre\",\n",
       " \"I actually wouldn't regret the artist\",\n",
       " \"I actually wouldn't dread the artist\",\n",
       " \"I actually wouldn't hate the guitar\",\n",
       " \"I actually shouldn't regret the album\",\n",
       " \"I actually couldn't despise the compilation\",\n",
       " \"I actually shouldn't regret the band\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Contrary to what i thought, the artist, wasn't hard\",\n",
       " \"Contrary to what i thought, the drummer, wasn't rough\",\n",
       " \"Contrary to what i thought, the ep, wasn't terrible\",\n",
       " \"Contrary to what i thought, the band, wasn't nasty\",\n",
       " \"Contrary to what i thought, the project, wasn't frustrating\",\n",
       " \"Contrary to what i thought, the guitarist, wasn't terrible\",\n",
       " \"Contrary to what i thought, the drummer, wasn't sad\",\n",
       " \"Contrary to what i thought, the band, wasn't ridiculous\",\n",
       " \"Contrary to what i thought, the album, wasn't poor\",\n",
       " \"Contrary to what i thought, the artist, wasn't unpleasant\",\n",
       " \"Contrary to what i thought, the genre, wasn't bad\",\n",
       " \"Contrary to what i thought, the compilation, wasn't annoying\",\n",
       " \"Contrary to what i thought, the compilation, wasn't ridiculous\",\n",
       " \"Contrary to what i thought, the compilation, wasn't average\",\n",
       " \"Contrary to what i thought, the ep, wasn't weird\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
